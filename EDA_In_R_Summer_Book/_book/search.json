[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data 7 Exploratory Data Analysis In R Workshops Companion Book",
    "section": "",
    "text": "Here you will find a collection of Exploratory Data Analysis in R Workshops prepared by the staff of the Data Science Institute\n\n\n\n\n\n\nExploring a novel data set and produce publication quality tables and reports\n\n\n\n\n\n\n\nExploring the normality of numerical columns in a novel data set and producing publication quality tables and reports\n\nVisit our available Digital Learning Resources Library!\n\nCreated: 07/22/2022 (G. Chism); Last up date: 07/22/2022\n CC BY-NC-SA"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Image Credit: Choonghyun Ryu\nExploratory data analysis is an essential first step towards determining the validity of your data and should be performed throughout the data pipeline. However, EDA is often performed too late or not at all. The R programming language, specifically through the RStudio IDE, is widely used open source platform for data analysis and data visualization. This is because of the extensive variety of packages available and attentive community devoted to data analysis. Consequently, there are several exploratory data analysis packages, each of which have their own pros and cons.\nHere, we utilize the dlookr package to conduct preliminary exploratory data analysis aimed at diagnosing any major issues with an imported data set. dlookr offers a clean and straightforward methodology to uncover issues such as data outliers, missing data, as well as summary statistical reports."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "intro.html#exploratory-data-analysis-in-r---diagnosing-like-a-data-doctor",
    "href": "intro.html#exploratory-data-analysis-in-r---diagnosing-like-a-data-doctor",
    "title": "1  Introduction",
    "section": "1.2 Exploratory data analysis in R - Diagnosing like a data doctor",
    "text": "1.2 Exploratory data analysis in R - Diagnosing like a data doctor\n\n1.2.1 Purpose of workshop\nExploring a novel data set and produce publication quality tables and reports"
  },
  {
    "objectID": "intro.html#exploratory-data-analysis-in-r---exploring-like-a-data-adventurer",
    "href": "intro.html#exploratory-data-analysis-in-r---exploring-like-a-data-adventurer",
    "title": "1  Introduction",
    "section": "1.3 Exploratory data analysis in R - Exploring like a data adventurer",
    "text": "1.3 Exploratory data analysis in R - Exploring like a data adventurer\n\n1.3.1 Purpose of the workshop\nExploring the normality of numerical columns in a novel data set and producing publication quality tables and reports\n\nVisit our available Digital Learning Resources Library!\n\nCreated: 07/22/2022 (G. Chism); Last up date: 07/22/2022\n CC BY-NC-SA"
  },
  {
    "objectID": "intro.html#what-are-some-important-data-set-characteristics",
    "href": "intro.html#what-are-some-important-data-set-characteristics",
    "title": "1  Introduction",
    "section": "1.1 What are Some Important Data Set Characteristics?",
    "text": "1.1 What are Some Important Data Set Characteristics?\nThere are several characteristics that are arguably important, but we will only consider those covered in this workshop series. Let’s start with the fundamentals that will help guide us."
  },
  {
    "objectID": "intro.html#diagnostics",
    "href": "intro.html#diagnostics",
    "title": "1  Introduction",
    "section": "1.2 Diagnostics",
    "text": "1.2 Diagnostics\nWhen importing data sets, it is important to consider characteristics about the data columns, rows, and individual cells.\n\n\n1.2.1 Variables\nName of each variable\n\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\n33.6\n\n\n0.627\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n26.6\n\n\n0.351\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23.3\n\n\n0.672\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28.1\n\n\n0.167\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43.1\n\n\n2.288\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n25.6\n\n\n0.201\n\n\n30\n\n\n0\n\n\nYoung\n\n\n\n\n\n\n\n\n\n1.2.2 Types\nData type of each variable\n\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\n\n\n\n\nPregnancies\n\n\ninteger\n\n\n\n\nGlucose\n\n\ninteger\n\n\n\n\nBloodPressure\n\n\ninteger\n\n\n\n\nSkinThickness\n\n\ninteger\n\n\n\n\nInsulin\n\n\ninteger\n\n\n\n\nBMI\n\n\nnumeric\n\n\n\n\nDiabetesPedigreeFunction\n\n\nnumeric\n\n\n\n\nAge\n\n\ninteger\n\n\n\n\nOutcome\n\n\ninteger\n\n\n\n\nAge_group\n\n\nfactor\n\n\n\n\n\n\n\n\n1.2.2.1 Numerical: Continuous\nMeasurable numbers that are fractional or decimal and cannot be counted (e.g., time, height, weight)\n\n\n\n\n\n\n\n1.2.2.2 Numerical: Discrete\nCountable whole numbers or integers (e.g., number of successes or failures)\n\n\n\n\n\n\n\n\n1.2.2.3 Categorical: Nominal\nLabeling variables without any order or quantitative value (e.g., hair color, nationality)\n\n\n\n\n\n\n\n1.2.2.4 Categorical: Ordinal\nWhere there is a hierarchical order along a scale (e.g., ranks, letter grades, age groups)\n\n\n\n\n\n\n\n\n1.2.3 Missing Values (NAs)\nCells, rows, or columns without data\n\nMissing percent: percentage of missing values * Unique count: number of unique values.\nUnique rate: rate of unique value - unique count / total number of observations.\n\n\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\nNA\n\n\nNA\n\n\n35\n\n\n0\n\n\n33.6\n\n\n0.627\n\n\n50\n\n\n1\n\n\nNA\n\n\n\n\n1\n\n\n85\n\n\nNA\n\n\n29\n\n\nNA\n\n\n26.6\n\n\n0.351\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\nNA\n\n\n23.3\n\n\n0.672\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\nNA\n\n\n35\n\n\nNA\n\n\n43.1\n\n\n2.288\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\nNA\n\n\n0\n\n\n0\n\n\n25.6\n\n\n0.201\n\n\n30\n\n\n0\n\n\nYoung"
  },
  {
    "objectID": "intro.html#summary-statistics-numerical-variables",
    "href": "intro.html#summary-statistics-numerical-variables",
    "title": "1  Introduction",
    "section": "1.4 Summary statistics: numerical variables",
    "text": "1.4 Summary statistics: numerical variables"
  },
  {
    "objectID": "intro.html#getting-started-with-the-dlookr-r-package-exploring-a-novel-data-set-and-produce-publication-quality-tables-and-reports",
    "href": "intro.html#getting-started-with-the-dlookr-r-package-exploring-a-novel-data-set-and-produce-publication-quality-tables-and-reports",
    "title": "1  Introduction",
    "section": "1.1 Getting started with the dlookr R package: Exploring a novel data set and produce publication quality tables and reports",
    "text": "1.1 Getting started with the dlookr R package: Exploring a novel data set and produce publication quality tables and reports\nExploratory data analysis is an essential first step towards determining the validity of your data and should be performed throughout the data pipeline. However, EDA is often performed too late or not at all. The R programming language, specifically through the RStudio IDE, is widely used open source platform for data analysis and data visualization. This is because of the extensive variety of packages available and attentive community devoted to data analysis. Consequently, there are several exploratory data analysis packages, each of which have their own pros and cons.\nHere, we utilize the dlookr package to conduct preliminary exploratory data analysis aimed at diagnosing any major issues with an imported data set. dlookr offers a clean and straightforward methodology to uncover issues such as data outliers, missing data, as well as summary statistical reports.\n\n\n1.1.1 What is exploratory data analysis?\nExploratory data analysis is a statistical, approach towards analyzing data sets to investigate and summarize their main characteristics, often through statistical graphics and other data visualization methods."
  },
  {
    "objectID": "intro.html#summary-statistics",
    "href": "intro.html#summary-statistics",
    "title": "1  Introduction",
    "section": "1.3 Summary Statistics",
    "text": "1.3 Summary Statistics\nAbove we described some properties of data. However, you will need to know some descriptive characteristics of your data before you can move forward. Enter, summary statistics.\nSummary statistics allow you to summarize large amounts of information about your data as quickly as possible.\n\n1.3.1 Central Tendency\nMeasuring a central property of your data. Some examples you’ve probably heard of are:\n\nMean: Average value\nMedian: Middle value\nMode: Most common value\n\n\n\n\n\n\nNotice however, that all values of central tendency can be pretty similar, such as in the top panel. This will become important when we discuss data transformations in Chapter 3.\n\n\n1.3.2 Statistical Dispersion\nMeasure of data variability, scatter, or spread. Some examples you may have heard of:\n\nStandard deviation (SD): The amount of variation that occurs in a set of values.\nInterquartile range (IQR): The difference between the 75th and 25th percentiles\nOutliers: A value outside of \\(1.5 * IQR\\)\n\n\n\n\n\n\n\n\n1.3.3 Distribution Shape\nMeasures of describing the shape of a distribution, usually compared to a normal distribution (bell-curve)\n\nSkewness: The symmetry of the distribution\nKurtosis: The tailedness of the distribution\n\n\n\n\n\n\n\n\n1.3.4 Statistical Dependence (Correlation)\nMeasure of causality between two random variables (statistically). Notably, we approximate causality with correlations (see correlation \\(\\neq\\) causation)\n\nNumerical values, but you can compare numericals across categories (see the first plot above)."
  },
  {
    "objectID": "intro.html#distribution-shape",
    "href": "intro.html#distribution-shape",
    "title": "1  Introduction",
    "section": "1.4 Distribution Shape",
    "text": "1.4 Distribution Shape\nMeasures of describing the shape of a distribution, usually compared to a normal distribution (bell-curve)\n\nSkewness: The symmetry of the distribution\nKurtosis: The tailedness of the distribution"
  },
  {
    "objectID": "EDA_In_R_Summer1.html",
    "href": "EDA_In_R_Summer1.html",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "",
    "text": "Exploring a novel data set and produce publication quality tables and reports"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#objectives",
    "href": "EDA_In_R_Summer1.html#objectives",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "2.2 Objectives",
    "text": "2.2 Objectives\n\nLoad and explore a data set with publication quality tables\nDiagnose outliers and missing values in a data set\nPrepare an HTML summary report showcasing properties of a data set"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#summary-statistics",
    "href": "EDA_In_R_Summer1.html#summary-statistics",
    "title": "2  Exploratory data analysis in R - Diagnosing like a data doctor",
    "section": "2.4 Summary Statistics",
    "text": "2.4 Summary Statistics\nAbove we described some properties of data. However, you will need to know some descriptive characteristics of your data before you can move forward. Enter, summary statistics.\nSummary statistics allow you to summarize large amounts of information about your data as quickly as possible.\n\n\n2.4.1 Central Tendency\nMeasuring a central property of your data. Some examples you’ve probably heard of are:\n\nMean: Average value\nMedian: Middle value\nMode: Most common value\n\n\n\n\n\n\nNotice however, that all values of central tendency can be pretty similar, such as in the top panel. This will become important when we discuss data transformations in Chapter 3.\n\n\n\n2.4.2 Statistical Dispersion\nMeasure of data variability, scatter, or spread. Some examples you may have heard of:\n\nStandard deviation (SD): The amount of variation that occurs in a set of values.\nInterquartile range (IQR): The difference between the 75th and 25th percentiles"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#required-setup",
    "href": "EDA_In_R_Summer1.html#required-setup",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "2.3 Required Setup",
    "text": "2.3 Required Setup\nWe first need to prepare our environment with the necessary packages\n\n# Sets the number of significant figures to two - e.g., 0.01\noptions(digits = 2)\n\n# Required package for quick package downloading and loading \ninstall.packages(\"pacman\")\n\n# Downloads and load required packages\npacman::p_load(dlookr, # Exploratory data analysis\n               formattable, # HTML tables from R outputs\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               missRanger, # To generate NAs\n               tidyverse) # Powerful data wrangling package suite\n\n\n\n2.3.1 Load and Examine a Data Set\n\nLoad data and view\nExamine columns and data types\nDefine box plots\nDescribe meta data\n\n\n# Let's load a data set from the flights data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"diabetes.csv\")) |>\n  # Add a categorical group\n  mutate(Age_group = ifelse(Age >= 21 & Age <= 30, \"Young\", \n                            ifelse(Age > 30 & Age <= 50, \"Middle\", \n                                   \"Elderly\")),\n         Age_group = fct_rev(Age_group))\n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28\n\n\n0.17\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n26\n\n\n0.20\n\n\n30\n\n\n0\n\n\nYoung"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#summary-statistics-of-your-data",
    "href": "EDA_In_R_Summer1.html#summary-statistics-of-your-data",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "2.5 Summary Statistics of your Data",
    "text": "2.5 Summary Statistics of your Data\n\n2.5.1 Numerical Variables\n\ndataset |>\n  diagnose_numeric() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\nmin\n\n\nQ1\n\n\nmean\n\n\nmedian\n\n\nQ3\n\n\nmax\n\n\nzero\n\n\nminus\n\n\noutlier\n\n\n\n\n\n\nPregnancies\n\n\n0.000\n\n\n1.00\n\n\n3.85\n\n\n3.00\n\n\n6.00\n\n\n17.0\n\n\n111\n\n\n0\n\n\n4\n\n\n\n\nGlucose\n\n\n0.000\n\n\n99.00\n\n\n120.89\n\n\n117.00\n\n\n140.25\n\n\n199.0\n\n\n5\n\n\n0\n\n\n5\n\n\n\n\nBloodPressure\n\n\n0.000\n\n\n62.00\n\n\n69.11\n\n\n72.00\n\n\n80.00\n\n\n122.0\n\n\n35\n\n\n0\n\n\n45\n\n\n\n\nSkinThickness\n\n\n0.000\n\n\n0.00\n\n\n20.54\n\n\n23.00\n\n\n32.00\n\n\n99.0\n\n\n227\n\n\n0\n\n\n1\n\n\n\n\nInsulin\n\n\n0.000\n\n\n0.00\n\n\n79.80\n\n\n30.50\n\n\n127.25\n\n\n846.0\n\n\n374\n\n\n0\n\n\n34\n\n\n\n\nBMI\n\n\n0.000\n\n\n27.30\n\n\n31.99\n\n\n32.00\n\n\n36.60\n\n\n67.1\n\n\n11\n\n\n0\n\n\n19\n\n\n\n\nDiabetesPedigreeFunction\n\n\n0.078\n\n\n0.24\n\n\n0.47\n\n\n0.37\n\n\n0.63\n\n\n2.4\n\n\n0\n\n\n0\n\n\n29\n\n\n\n\nAge\n\n\n21.000\n\n\n24.00\n\n\n33.24\n\n\n29.00\n\n\n41.00\n\n\n81.0\n\n\n0\n\n\n0\n\n\n9\n\n\n\n\nOutcome\n\n\n0.000\n\n\n0.00\n\n\n0.35\n\n\n0.00\n\n\n1.00\n\n\n1.0\n\n\n500\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\nmin: minimum value\nQ1: 1/4 quartile, 25th percentile\nmean: arithmetic mean (average value)\nmedian: median, 50th percentile\nQ3: 3/4 quartile, 75th percentile\nmax: maximum value\nzero: number of observations with the value 0\nminus: number of observations with negative numbers\noutlier: number of outliers\n\n\n\n\n2.5.2 Outliers\nValues outside of \\(1.5 * IQR\\)\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\nThere are several numerical variables that have outliers above, let’s see what the data look like with and without them\n\nCreate a table with columns containing outliers\nPlot outliers in a box plot and histogram\n\n\n# Table showing outliers\ndiagnose_outlier(dataset) |>\n  filter(outliers_ratio > 0) |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\noutliers_cnt\n\n\noutliers_ratio\n\n\noutliers_mean\n\n\nwith_mean\n\n\nwithout_mean\n\n\n\n\n\n\nPregnancies\n\n\n4\n\n\n0.52\n\n\n15.0\n\n\n3.85\n\n\n3.79\n\n\n\n\nGlucose\n\n\n5\n\n\n0.65\n\n\n0.0\n\n\n120.89\n\n\n121.69\n\n\n\n\nBloodPressure\n\n\n45\n\n\n5.86\n\n\n19.2\n\n\n69.11\n\n\n72.21\n\n\n\n\nSkinThickness\n\n\n1\n\n\n0.13\n\n\n99.0\n\n\n20.54\n\n\n20.43\n\n\n\n\nInsulin\n\n\n34\n\n\n4.43\n\n\n457.0\n\n\n79.80\n\n\n62.33\n\n\n\n\nBMI\n\n\n19\n\n\n2.47\n\n\n23.7\n\n\n31.99\n\n\n32.20\n\n\n\n\nDiabetesPedigreeFunction\n\n\n29\n\n\n3.78\n\n\n1.5\n\n\n0.47\n\n\n0.43\n\n\n\n\nAge\n\n\n9\n\n\n1.17\n\n\n70.0\n\n\n33.24\n\n\n32.81\n\n\n\n\n\n\n\n\noutliers_cnt: number of outliers\noutliers_ratio: ratio of outliers over all values\noutliers_mean: arithmetic mean (average value) of outlier values\nwith_mean: arithmetic mean of all values including outliers\nwithout_mean: arithmetic mean of all values excluding outliers\n\n\n# Selecting desired columns \ndataset %>% \n  select(BloodPressure, BMI, Age) %>%\n    plot_outlier()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.3 Missing Values (NAs)\n\nTable showing the extent of NAs in columns containing them\nPlot showing the frequency of missing values\n\n\n# Randomly generate NAs\nna.dataset <- dataset |>\n  generateNA(p = 0.2)\n\nna.dataset |>\nhead() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\nNA\n\n\n72\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\nNA\n\n\n1\n\n\nMiddle\n\n\n\n\nNA\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28\n\n\n0.17\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\nNA\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n26\n\n\n0.20\n\n\nNA\n\n\nNA\n\n\nYoung\n\n\n\n\n\n\n\n\n# Create the NA table\nna.dataset |>\n  plot_na_pareto(only_na = TRUE, plot = FALSE) |>\n  formattable() # Publishable table\n\n\n\n\n\n\nvariable\n\n\nfrequencies\n\n\nratio\n\n\ngrade\n\n\ncumulative\n\n\n\n\n\n\nAge\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n10\n\n\n\n\nAge_group\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n20\n\n\n\n\nBloodPressure\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n30\n\n\n\n\nBMI\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n40\n\n\n\n\nDiabetesPedigreeFunction\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n50\n\n\n\n\nGlucose\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n60\n\n\n\n\nInsulin\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n70\n\n\n\n\nOutcome\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n80\n\n\n\n\nPregnancies\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n90\n\n\n\n\nSkinThickness\n\n\n154\n\n\n0.2\n\n\nBad\n\n\n100\n\n\n\n\n\n\n\n\n# Plot the intersect of the columns with the most missing values\n# This means that some combinations of columns have missing values in the same row\nna.dataset |>\n  select(BloodPressure, Glucose, Age) |>\n  plot_na_intersect(only_na = TRUE) \n\n\n\n\n\n\n2.5.4 Categorical Variables\n\ndataset |>\n  diagnose_category() |> \n  formattable()\n\n\n\n\n\n\nvariables\n\n\nlevels\n\n\nN\n\n\nfreq\n\n\nratio\n\n\nrank\n\n\n\n\n\n\nAge_group\n\n\nYoung\n\n\n768\n\n\n417\n\n\n54\n\n\n1\n\n\n\n\nAge_group\n\n\nMiddle\n\n\n768\n\n\n270\n\n\n35\n\n\n2\n\n\n\n\nAge_group\n\n\nElderly\n\n\n768\n\n\n81\n\n\n11\n\n\n3\n\n\n\n\n\n\n\n\nvariables: category names\nlevels: group names within categories\nN: number of observation\nfreq: number of observation at group level / number of observation at category level\nratio: percentage of observation at group level / number of observation at category level\nrank: rank of the occupancy ratio of levels (order in which the groups are in the category)"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#diagnose-outliers-and-missing-values",
    "href": "EDA_In_R_Summer1.html#diagnose-outliers-and-missing-values",
    "title": "2  Exploratory data analysis in R - Diagnosing like a data doctor",
    "section": "2.6 Diagnose outliers and missing values",
    "text": "2.6 Diagnose outliers and missing values\n\n2.6.1 Outliers: values outside of \\(1.5 * IQR\\)\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\nThere are several numerical variables that have outliers above, let’s see what the data look like with and without them\n\nCreate a table with columns containing outliers\nPlot outliers in a box plot and histogram\n\n\n# Table showing outliers\nformattable(diagnose_outlier(dataset) %>%\n  filter(outliers_ratio > 0))\n\n\n\n\n\n\nvariables\n\n\noutliers_cnt\n\n\noutliers_ratio\n\n\noutliers_mean\n\n\nwith_mean\n\n\nwithout_mean\n\n\n\n\n\n\nPregnancies\n\n\n4\n\n\n0.52\n\n\n15.0\n\n\n3.85\n\n\n3.79\n\n\n\n\nGlucose\n\n\n5\n\n\n0.65\n\n\n0.0\n\n\n120.89\n\n\n121.69\n\n\n\n\nBloodPressure\n\n\n45\n\n\n5.86\n\n\n19.2\n\n\n69.11\n\n\n72.21\n\n\n\n\nSkinThickness\n\n\n1\n\n\n0.13\n\n\n99.0\n\n\n20.54\n\n\n20.43\n\n\n\n\nInsulin\n\n\n34\n\n\n4.43\n\n\n457.0\n\n\n79.80\n\n\n62.33\n\n\n\n\nBMI\n\n\n19\n\n\n2.47\n\n\n23.7\n\n\n31.99\n\n\n32.20\n\n\n\n\nDiabetesPedigreeFunction\n\n\n29\n\n\n3.78\n\n\n1.5\n\n\n0.47\n\n\n0.43\n\n\n\n\nAge\n\n\n9\n\n\n1.17\n\n\n70.0\n\n\n33.24\n\n\n32.81\n\n\n\n\n\n\n\n\noutliers_cnt: number of outliers\noutliers_ratio: ratio of outliers over all values\noutliers_mean: arithmetic mean (average value) of outlier values\nwith_mean: arithmetic mean of all values including outliers\nwithout_mean: arithmetic mean of all values excluding outliers\n\n\n# Selecting desired columns \ndataset %>% \n  select(BloodPressure, BMI, Age) %>%\n    plot_outlier()"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#categorical-variables",
    "href": "EDA_In_R_Summer1.html#categorical-variables",
    "title": "2  Exploratory data analysis in R - Diagnosing like a data doctor",
    "section": "2.7 Categorical variables",
    "text": "2.7 Categorical variables\n\ndiagnose_category(dataset) |> formattable()\n\n\n\n\n\n\nvariables\n\n\nlevels\n\n\nN\n\n\nfreq\n\n\nratio\n\n\nrank\n\n\n\n\n\n\nAge_group\n\n\nYoung\n\n\n768\n\n\n417\n\n\n54\n\n\n1\n\n\n\n\nAge_group\n\n\nMiddle\n\n\n768\n\n\n270\n\n\n35\n\n\n2\n\n\n\n\nAge_group\n\n\nElderly\n\n\n768\n\n\n81\n\n\n11\n\n\n3\n\n\n\n\n\n\n\n\nvariables: category names\nlevels: group names within categories\nN: number of observation\nfreq: number of observation at group level / number of observation at category level\nratio: percentage of observation at group level / number of observation at category level\nrank: rank of the occupancy ratio of levels (order in which the groups are in the category)"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#missing-values-nas",
    "href": "EDA_In_R_Summer1.html#missing-values-nas",
    "title": "2  Exploratory data analysis in R - Diagnosing like a data doctor",
    "section": "2.8 Missing values (NAs)",
    "text": "2.8 Missing values (NAs)\n\nTable showing the extent of NAs in columns containing them\nPlot showing the frequency of missing values\n\n\n# Randomly generate NAs\nna.dataset <- dataset |>\n  dplyr::mutate_all(~ifelse(sample(c(TRUE, FALSE), size = length(.), replace =\n                                     TRUE, prob = c(0.8, 0.2)),\n                            as.character(.), NA)) \nna.dataset |>\nhead() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\nNA\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\nNA\n\n\n0.627\n\n\n50\n\n\nNA\n\n\nNA\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\nNA\n\n\n0.351\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\nNA\n\n\n64\n\n\n0\n\n\n0\n\n\n23.3\n\n\n0.672\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\nNA\n\n\n89\n\n\nNA\n\n\n23\n\n\n94\n\n\n28.1\n\n\nNA\n\n\nNA\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\nNA\n\n\n40\n\n\n35\n\n\n168\n\n\n43.1\n\n\n2.288\n\n\nNA\n\n\n1\n\n\nNA\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n25.6\n\n\n0.201\n\n\n30\n\n\n0\n\n\nNA\n\n\n\n\n\n\n\n\n# Create the NA table\nplot_na_pareto(na.dataset, only_na = TRUE, plot = FALSE) |>\nformattable() # Publishable table\n\n\n\n\n\n\nvariable\n\n\nfrequencies\n\n\nratio\n\n\ngrade\n\n\ncumulative\n\n\n\n\n\n\nGlucose\n\n\n163\n\n\n0.21\n\n\nBad\n\n\n11\n\n\n\n\nOutcome\n\n\n163\n\n\n0.21\n\n\nBad\n\n\n21\n\n\n\n\nSkinThickness\n\n\n163\n\n\n0.21\n\n\nBad\n\n\n32\n\n\n\n\nDiabetesPedigreeFunction\n\n\n156\n\n\n0.20\n\n\nBad\n\n\n42\n\n\n\n\nPregnancies\n\n\n156\n\n\n0.20\n\n\nBad\n\n\n52\n\n\n\n\nAge_group\n\n\n152\n\n\n0.20\n\n\nNotBad\n\n\n62\n\n\n\n\nAge\n\n\n150\n\n\n0.20\n\n\nNotBad\n\n\n72\n\n\n\n\nInsulin\n\n\n150\n\n\n0.20\n\n\nNotBad\n\n\n81\n\n\n\n\nBloodPressure\n\n\n146\n\n\n0.19\n\n\nNotBad\n\n\n91\n\n\n\n\nBMI\n\n\n141\n\n\n0.18\n\n\nNotBad\n\n\n100\n\n\n\n\n\n\n\n\n# Plot the intersect of the columns with the most missing values\n# This means that some combinations of columns have missing values in the same row\nna.dataset |>\n  select(BloodPressure, Glucose, Age) |>\n  plot_na_intersect(only_na = TRUE)"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#produce-an-html-summary-of-a-data-set",
    "href": "EDA_In_R_Summer1.html#produce-an-html-summary-of-a-data-set",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "2.6 Produce an HTML Summary of a Data Set",
    "text": "2.6 Produce an HTML Summary of a Data Set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n#diagnose_web_report(dataset)"
  },
  {
    "objectID": "EDA_In_R_Summer1.html#diagnose-your-data",
    "href": "EDA_In_R_Summer1.html#diagnose-your-data",
    "title": "2  Exploratory Data Analysis in R - Diagnosing Like a Data Doctor",
    "section": "2.4 Diagnose your Data",
    "text": "2.4 Diagnose your Data\n\n# What are the properties of the data\ndataset |>\n  diagnose() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\nmissing_count\n\n\nmissing_percent\n\n\nunique_count\n\n\nunique_rate\n\n\n\n\n\n\nPregnancies\n\n\ninteger\n\n\n0\n\n\n0\n\n\n17\n\n\n0.0221\n\n\n\n\nGlucose\n\n\ninteger\n\n\n0\n\n\n0\n\n\n136\n\n\n0.1771\n\n\n\n\nBloodPressure\n\n\ninteger\n\n\n0\n\n\n0\n\n\n47\n\n\n0.0612\n\n\n\n\nSkinThickness\n\n\ninteger\n\n\n0\n\n\n0\n\n\n51\n\n\n0.0664\n\n\n\n\nInsulin\n\n\ninteger\n\n\n0\n\n\n0\n\n\n186\n\n\n0.2422\n\n\n\n\nBMI\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n248\n\n\n0.3229\n\n\n\n\nDiabetesPedigreeFunction\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n517\n\n\n0.6732\n\n\n\n\nAge\n\n\ninteger\n\n\n0\n\n\n0\n\n\n52\n\n\n0.0677\n\n\n\n\nOutcome\n\n\ninteger\n\n\n0\n\n\n0\n\n\n2\n\n\n0.0026\n\n\n\n\nAge_group\n\n\nfactor\n\n\n0\n\n\n0\n\n\n3\n\n\n0.0039\n\n\n\n\n\n\n\n\nvariables: name of each variable\ntypes: data type of each variable\nmissing_count: number of missing values\nmissing_percent: percentage of missing values\nunique_count: number of unique values\nunique_rate: rate of unique value - unique_count / number of observations"
  },
  {
    "objectID": "EDA_In_R_Summer2.html",
    "href": "EDA_In_R_Summer2.html",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "",
    "text": "Exploring the normality of numerical columns in a novel data set and producing publication quality tables and reports"
  },
  {
    "objectID": "EDA_In_R_Summer2.html#objectives",
    "href": "EDA_In_R_Summer2.html#objectives",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.2 Objectives",
    "text": "3.2 Objectives\n\nUsing summary statistics to better understand individual columns in a data set.\nAssessing data normality in numerical columns.\nProducing a publishable HTML with summary statistics and normality tests for columns within a data set."
  },
  {
    "objectID": "EDA_In_R_Summer2.html#required-setup",
    "href": "EDA_In_R_Summer2.html#required-setup",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.3 Required Setup",
    "text": "3.3 Required Setup\nWe first need to prepare our environment with the necessary packages\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\noptions(digits = 2)\n\ninstall.packages(\"pacman\")\n\npacman::p_load(dlookr, # Exploratory data analysis\n               formattable, # HTML tables from R outputs\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               tidyverse) # Powerful data wrangling package suite\n\n\n\n3.3.1 Load and Examine a Data Set\n\n# Let's load a data set from the flights data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"diabetes.csv\")) |>\n  # Add a categorical group\n  mutate(Age_group = ifelse(Age >= 21 & Age <= 30, \"Young\", \n                            ifelse(Age > 30 & Age <=50, \"Middle\", \n                                   \"Elderly\")),\n         Age_group = fct_rev(Age_group))\n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28\n\n\n0.17\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n26\n\n\n0.20\n\n\n30\n\n\n0\n\n\nYoung"
  },
  {
    "objectID": "EDA_In_R_Summer2.html#diagnose-your-data",
    "href": "EDA_In_R_Summer2.html#diagnose-your-data",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.4 Diagnose your Data",
    "text": "3.4 Diagnose your Data\n\n# What are the properties of the data\ndataset |>\n  diagnose() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\nmissing_count\n\n\nmissing_percent\n\n\nunique_count\n\n\nunique_rate\n\n\n\n\n\n\nPregnancies\n\n\ninteger\n\n\n0\n\n\n0\n\n\n17\n\n\n0.0221\n\n\n\n\nGlucose\n\n\ninteger\n\n\n0\n\n\n0\n\n\n136\n\n\n0.1771\n\n\n\n\nBloodPressure\n\n\ninteger\n\n\n0\n\n\n0\n\n\n47\n\n\n0.0612\n\n\n\n\nSkinThickness\n\n\ninteger\n\n\n0\n\n\n0\n\n\n51\n\n\n0.0664\n\n\n\n\nInsulin\n\n\ninteger\n\n\n0\n\n\n0\n\n\n186\n\n\n0.2422\n\n\n\n\nBMI\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n248\n\n\n0.3229\n\n\n\n\nDiabetesPedigreeFunction\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n517\n\n\n0.6732\n\n\n\n\nAge\n\n\ninteger\n\n\n0\n\n\n0\n\n\n52\n\n\n0.0677\n\n\n\n\nOutcome\n\n\ninteger\n\n\n0\n\n\n0\n\n\n2\n\n\n0.0026\n\n\n\n\nAge_group\n\n\nfactor\n\n\n0\n\n\n0\n\n\n3\n\n\n0.0039\n\n\n\n\n\n\n\n\nvariables: name of each variable\ntypes: data type of each variable\nmissing_count: number of missing values\nmissing_percent: percentage of missing values\nunique_count: number of unique values\nunique_rate: rate of unique value - unique_count / number of observations\n\n\n\n3.4.1 Box Plot\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\n\n\n3.4.2 Skewness\n\n\n\n(c) Andrey Akinshin\n\n\n\n\n3.4.2.1 NOTE\n\n“Skewness” has multiple definitions. Several underlying equations mey be at play\nSkewness is “designed” for distributions with one peak (unimodal); it’s meaningless for distributions with multiple peaks (multimodal).\nMost default skewness definitions are not robust: a single outlier could completely distort the skewness value.\nWe can’t make conclusions about the locations of the mean and the median based on the skewness sign.\n\n\n\n\n\n3.4.3 Kurtosis\n\n\n\n(c) Andrey Akinshin\n\n\n\nNOTE\n\nThere are multiple definitions of kurtosis - i.e., “kurtosis” and “excess kurtosis,” but there are other definitions of this measure.\nKurtosis may work fine for distributions with one peak (unimodal); it’s meaningless for distributions with multiple peaks (multimodal).\nThe classic definition of kurtosis is not robust: it could be easily spoiled by extreme outliers."
  },
  {
    "objectID": "EDA_In_R_Summer2.html#describe-your-continuous-data",
    "href": "EDA_In_R_Summer2.html#describe-your-continuous-data",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.5 Describe your Continuous Data",
    "text": "3.5 Describe your Continuous Data\n\n# Summary statistics \ndataset |>\n  describe() |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np00\n\n\np01\n\n\np05\n\n\np10\n\n\np20\n\n\np25\n\n\np30\n\n\np40\n\n\np50\n\n\np60\n\n\np70\n\n\np75\n\n\np80\n\n\np90\n\n\np95\n\n\np99\n\n\np100\n\n\n\n\n\n\nPregnancies\n\n\n768\n\n\n0\n\n\n3.85\n\n\n3.37\n\n\n0.122\n\n\n5.00\n\n\n0.90\n\n\n0.16\n\n\n0.000\n\n\n0.000\n\n\n0.00\n\n\n0.00\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n2.0\n\n\n3.00\n\n\n4.00\n\n\n5.00\n\n\n6.00\n\n\n7.00\n\n\n9.00\n\n\n10.0\n\n\n13.0\n\n\n17.0\n\n\n\n\nGlucose\n\n\n768\n\n\n0\n\n\n120.89\n\n\n31.97\n\n\n1.154\n\n\n41.25\n\n\n0.17\n\n\n0.64\n\n\n0.000\n\n\n57.000\n\n\n79.00\n\n\n85.00\n\n\n95.00\n\n\n99.00\n\n\n102.00\n\n\n109.0\n\n\n117.00\n\n\n125.00\n\n\n134.00\n\n\n140.25\n\n\n147.00\n\n\n167.00\n\n\n181.0\n\n\n196.0\n\n\n199.0\n\n\n\n\nBloodPressure\n\n\n768\n\n\n0\n\n\n69.11\n\n\n19.36\n\n\n0.698\n\n\n18.00\n\n\n-1.84\n\n\n5.18\n\n\n0.000\n\n\n0.000\n\n\n38.70\n\n\n54.00\n\n\n60.00\n\n\n62.00\n\n\n64.00\n\n\n68.0\n\n\n72.00\n\n\n74.00\n\n\n78.00\n\n\n80.00\n\n\n82.00\n\n\n88.00\n\n\n90.0\n\n\n106.0\n\n\n122.0\n\n\n\n\nSkinThickness\n\n\n768\n\n\n0\n\n\n20.54\n\n\n15.95\n\n\n0.576\n\n\n32.00\n\n\n0.11\n\n\n-0.52\n\n\n0.000\n\n\n0.000\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n8.20\n\n\n18.0\n\n\n23.00\n\n\n27.00\n\n\n31.00\n\n\n32.00\n\n\n35.00\n\n\n40.00\n\n\n44.0\n\n\n51.3\n\n\n99.0\n\n\n\n\nInsulin\n\n\n768\n\n\n0\n\n\n79.80\n\n\n115.24\n\n\n4.159\n\n\n127.25\n\n\n2.27\n\n\n7.21\n\n\n0.000\n\n\n0.000\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.0\n\n\n30.50\n\n\n72.20\n\n\n106.00\n\n\n127.25\n\n\n150.00\n\n\n210.00\n\n\n293.0\n\n\n519.9\n\n\n846.0\n\n\n\n\nBMI\n\n\n768\n\n\n0\n\n\n31.99\n\n\n7.88\n\n\n0.284\n\n\n9.30\n\n\n-0.43\n\n\n3.29\n\n\n0.000\n\n\n0.000\n\n\n21.80\n\n\n23.60\n\n\n25.90\n\n\n27.30\n\n\n28.20\n\n\n30.1\n\n\n32.00\n\n\n33.70\n\n\n35.49\n\n\n36.60\n\n\n37.80\n\n\n41.50\n\n\n44.4\n\n\n50.8\n\n\n67.1\n\n\n\n\nDiabetesPedigreeFunction\n\n\n768\n\n\n0\n\n\n0.47\n\n\n0.33\n\n\n0.012\n\n\n0.38\n\n\n1.92\n\n\n5.59\n\n\n0.078\n\n\n0.095\n\n\n0.14\n\n\n0.17\n\n\n0.22\n\n\n0.24\n\n\n0.26\n\n\n0.3\n\n\n0.37\n\n\n0.45\n\n\n0.56\n\n\n0.63\n\n\n0.69\n\n\n0.88\n\n\n1.1\n\n\n1.7\n\n\n2.4\n\n\n\n\nAge\n\n\n768\n\n\n0\n\n\n33.24\n\n\n11.76\n\n\n0.424\n\n\n17.00\n\n\n1.13\n\n\n0.64\n\n\n21.000\n\n\n21.000\n\n\n21.00\n\n\n22.00\n\n\n23.00\n\n\n24.00\n\n\n25.00\n\n\n27.0\n\n\n29.00\n\n\n33.00\n\n\n38.00\n\n\n41.00\n\n\n42.60\n\n\n51.00\n\n\n58.0\n\n\n67.0\n\n\n81.0\n\n\n\n\nOutcome\n\n\n768\n\n\n0\n\n\n0.35\n\n\n0.48\n\n\n0.017\n\n\n1.00\n\n\n0.64\n\n\n-1.60\n\n\n0.000\n\n\n0.000\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.0\n\n\n0.00\n\n\n0.00\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n1.0\n\n\n1.0\n\n\n1.0\n\n\n\n\n\n\n\n\nn : number of observations excluding missing values\nna : number of missing values\nmean : arithmetic average\nsd : standard deviation\nse_mean : standard error mean. sd/sqrt(n)\nIQR : interquartile range (Q3-Q1)\nskewness : skewness\nkurtosis : kurtosis\np25 : Q1. 25% percentile\np50 : median. 50% percentile\np75 : Q3. 75% percentile\np01, p05, p10, p20, p30 : 1%, 5%, 20%, 30% percentiles\np40, p60, p70, p80 : 40%, 60%, 70%, 80% percentiles\np90, p95, p99, p100 : 90%, 95%, 99%, 100% percentiles\n\n\n\n3.5.1 Describe your Continuous Data: Refined\nThe above is pretty overwhelming, and most people don’t care about percentiles outside of Q1, Q3, and the median (Q2).\n\n# Summary statistics, selecting the desired ones\ndataset %>%\n  describe() %>%\n  select(described_variables, n, na, mean, sd, se_mean, IQR, skewness, kurtosis, p25, p50, p75) |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np25\n\n\np50\n\n\np75\n\n\n\n\n\n\nPregnancies\n\n\n768\n\n\n0\n\n\n3.85\n\n\n3.37\n\n\n0.122\n\n\n5.00\n\n\n0.90\n\n\n0.16\n\n\n1.00\n\n\n3.00\n\n\n6.00\n\n\n\n\nGlucose\n\n\n768\n\n\n0\n\n\n120.89\n\n\n31.97\n\n\n1.154\n\n\n41.25\n\n\n0.17\n\n\n0.64\n\n\n99.00\n\n\n117.00\n\n\n140.25\n\n\n\n\nBloodPressure\n\n\n768\n\n\n0\n\n\n69.11\n\n\n19.36\n\n\n0.698\n\n\n18.00\n\n\n-1.84\n\n\n5.18\n\n\n62.00\n\n\n72.00\n\n\n80.00\n\n\n\n\nSkinThickness\n\n\n768\n\n\n0\n\n\n20.54\n\n\n15.95\n\n\n0.576\n\n\n32.00\n\n\n0.11\n\n\n-0.52\n\n\n0.00\n\n\n23.00\n\n\n32.00\n\n\n\n\nInsulin\n\n\n768\n\n\n0\n\n\n79.80\n\n\n115.24\n\n\n4.159\n\n\n127.25\n\n\n2.27\n\n\n7.21\n\n\n0.00\n\n\n30.50\n\n\n127.25\n\n\n\n\nBMI\n\n\n768\n\n\n0\n\n\n31.99\n\n\n7.88\n\n\n0.284\n\n\n9.30\n\n\n-0.43\n\n\n3.29\n\n\n27.30\n\n\n32.00\n\n\n36.60\n\n\n\n\nDiabetesPedigreeFunction\n\n\n768\n\n\n0\n\n\n0.47\n\n\n0.33\n\n\n0.012\n\n\n0.38\n\n\n1.92\n\n\n5.59\n\n\n0.24\n\n\n0.37\n\n\n0.63\n\n\n\n\nAge\n\n\n768\n\n\n0\n\n\n33.24\n\n\n11.76\n\n\n0.424\n\n\n17.00\n\n\n1.13\n\n\n0.64\n\n\n24.00\n\n\n29.00\n\n\n41.00\n\n\n\n\nOutcome\n\n\n768\n\n\n0\n\n\n0.35\n\n\n0.48\n\n\n0.017\n\n\n1.00\n\n\n0.64\n\n\n-1.60\n\n\n0.00\n\n\n0.00\n\n\n1.00"
  },
  {
    "objectID": "EDA_In_R_Summer2.html#describe-categorical-variables",
    "href": "EDA_In_R_Summer2.html#describe-categorical-variables",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.6 Describe Categorical Variables",
    "text": "3.6 Describe Categorical Variables\n\ndataset |>\n  diagnose_category() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\nlevels\n\n\nN\n\n\nfreq\n\n\nratio\n\n\nrank\n\n\n\n\n\n\nAge_group\n\n\nYoung\n\n\n768\n\n\n417\n\n\n54\n\n\n1\n\n\n\n\nAge_group\n\n\nMiddle\n\n\n768\n\n\n270\n\n\n35\n\n\n2\n\n\n\n\nAge_group\n\n\nElderly\n\n\n768\n\n\n81\n\n\n11\n\n\n3\n\n\n\n\n\n\n\n\nvariables: category names\nlevels: group names within categories\nN: number of observation\nfreq: number of observation at group level / number of observation at category level\nratio: percentage of observation at group level / number of observation at category level\nrank: rank of the occupancy ratio of levels (order in which the groups are in the category)\n\n\n\n3.6.1 Group Descriptive Statistics\n\ndataset |>\n  group_by(Age_group) |>\n  select(Glucose, Insulin, BMI, SkinThickness) |>\n  describe() |>\n  select(described_variables, Age_group, n, na, mean, sd, se_mean, IQR, skewness, kurtosis, p25, p50, p75) |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nAge_group\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np25\n\n\np50\n\n\np75\n\n\n\n\n\n\nBMI\n\n\nYoung\n\n\n417\n\n\n0\n\n\n31\n\n\n8.7\n\n\n0.43\n\n\n10.3\n\n\n-0.391\n\n\n3.081\n\n\n26\n\n\n31\n\n\n36\n\n\n\n\nBMI\n\n\nMiddle\n\n\n270\n\n\n0\n\n\n34\n\n\n6.2\n\n\n0.38\n\n\n7.6\n\n\n0.468\n\n\n0.022\n\n\n30\n\n\n33\n\n\n37\n\n\n\n\nBMI\n\n\nElderly\n\n\n81\n\n\n0\n\n\n30\n\n\n7.8\n\n\n0.87\n\n\n9.7\n\n\n-1.175\n\n\n4.027\n\n\n26\n\n\n30\n\n\n36\n\n\n\n\nGlucose\n\n\nYoung\n\n\n417\n\n\n0\n\n\n114\n\n\n28.7\n\n\n1.41\n\n\n34.0\n\n\n0.295\n\n\n1.575\n\n\n95\n\n\n110\n\n\n129\n\n\n\n\nGlucose\n\n\nMiddle\n\n\n270\n\n\n0\n\n\n126\n\n\n33.9\n\n\n2.06\n\n\n47.8\n\n\n-0.101\n\n\n0.448\n\n\n103\n\n\n123\n\n\n151\n\n\n\n\nGlucose\n\n\nElderly\n\n\n81\n\n\n0\n\n\n140\n\n\n31.3\n\n\n3.47\n\n\n48.0\n\n\n0.075\n\n\n-0.512\n\n\n114\n\n\n137\n\n\n162\n\n\n\n\nInsulin\n\n\nYoung\n\n\n417\n\n\n0\n\n\n84\n\n\n109.5\n\n\n5.36\n\n\n125.0\n\n\n2.021\n\n\n5.198\n\n\n0\n\n\n56\n\n\n125\n\n\n\n\nInsulin\n\n\nMiddle\n\n\n270\n\n\n0\n\n\n70\n\n\n107.8\n\n\n6.56\n\n\n125.0\n\n\n2.304\n\n\n7.787\n\n\n0\n\n\n0\n\n\n125\n\n\n\n\nInsulin\n\n\nElderly\n\n\n81\n\n\n0\n\n\n90\n\n\n159.4\n\n\n17.71\n\n\n156.0\n\n\n2.398\n\n\n6.934\n\n\n0\n\n\n0\n\n\n156\n\n\n\n\nSkinThickness\n\n\nYoung\n\n\n417\n\n\n0\n\n\n22\n\n\n14.7\n\n\n0.72\n\n\n20.0\n\n\n-0.078\n\n\n-0.848\n\n\n12\n\n\n23\n\n\n32\n\n\n\n\nSkinThickness\n\n\nMiddle\n\n\n270\n\n\n0\n\n\n20\n\n\n16.8\n\n\n1.02\n\n\n33.0\n\n\n-0.032\n\n\n-1.435\n\n\n0\n\n\n24\n\n\n33\n\n\n\n\nSkinThickness\n\n\nElderly\n\n\n81\n\n\n0\n\n\n16\n\n\n18.5\n\n\n2.05\n\n\n29.0\n\n\n1.345\n\n\n3.438\n\n\n0\n\n\n7\n\n\n29"
  },
  {
    "objectID": "EDA_In_R_Summer2.html#testing-normality",
    "href": "EDA_In_R_Summer2.html#testing-normality",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.7 Testing Normality",
    "text": "3.7 Testing Normality\n\nShapiro-Wilk test & Q-Q plots\nTesting overall normality of two columns\nTesting normality of groups\n\n\n\n3.7.1 Normality of Columns\n\n\n3.7.1.1 Shapiro-Wilk Test\nShapiro-Wilk test looks at whether a target distribution is sample form a normal distribution\n\ndataset |>\n  select(Glucose, Insulin, BMI, SkinThickness) |>\n  normality() |>\n  formattable()\n\n\n\n\n\n\nvars\n\n\nstatistic\n\n\np_value\n\n\nsample\n\n\n\n\n\n\nGlucose\n\n\n0.97\n\n\n2.0e-11\n\n\n768\n\n\n\n\nInsulin\n\n\n0.72\n\n\n7.9e-34\n\n\n768\n\n\n\n\nBMI\n\n\n0.95\n\n\n1.8e-15\n\n\n768\n\n\n\n\nSkinThickness\n\n\n0.90\n\n\n1.8e-21\n\n\n768\n\n\n\n\n\n\n\n\n\n\n3.7.1.2 Q-Q Plots\nPlots of the quartiles of a target data set and plot it against predicted quartiles from a normal distribution\n\ndataset |>\nplot_normality(Glucose, Insulin, BMI, SkinThickness)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.7.2 Normality within Groups\nLooking within Age_group at the subgroup normality\n\n3.7.2.1 Shapiro-Wilk Test\n\ndataset %>%\n  group_by(Age_group) %>%\n  select(Glucose, Insulin) %>%\n  normality() |>\n  formattable()\n\n\n\n\n\n\nvariable\n\n\nAge_group\n\n\nstatistic\n\n\np_value\n\n\nsample\n\n\n\n\n\n\nGlucose\n\n\nYoung\n\n\n0.95\n\n\n5.4e-10\n\n\n417\n\n\n\n\nGlucose\n\n\nMiddle\n\n\n0.98\n\n\n6.4e-04\n\n\n270\n\n\n\n\nGlucose\n\n\nElderly\n\n\n0.98\n\n\n1.4e-01\n\n\n81\n\n\n\n\nInsulin\n\n\nYoung\n\n\n0.76\n\n\n5.6e-24\n\n\n417\n\n\n\n\nInsulin\n\n\nMiddle\n\n\n0.69\n\n\n6.9e-22\n\n\n270\n\n\n\n\nInsulin\n\n\nElderly\n\n\n0.63\n\n\n6.2e-13\n\n\n81\n\n\n\n\n\n\n\n\n\n3.7.2.2 Q-Q Plots\n\ndataset %>%\n  group_by(Age_group) %>%\n  select(Glucose, Insulin) %>%\n  plot_normality()"
  },
  {
    "objectID": "EDA_In_R_Summer2.html#produce-an-html-normality-summary-of-a-data-set",
    "href": "EDA_In_R_Summer2.html#produce-an-html-normality-summary-of-a-data-set",
    "title": "3  Exploratory Data Analysis in R - Exploring Like a Data Adventurer",
    "section": "3.8 Produce an HTML normality summary of a data set",
    "text": "3.8 Produce an HTML normality summary of a data set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n#eda_web_report(dataset)"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html",
    "href": "DiagnosingLikeDataDoctor.html",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "",
    "text": "Exploring a novel data set and produce publication quality tables and reports"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#objectives",
    "href": "DiagnosingLikeDataDoctor.html#objectives",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.2 Objectives",
    "text": "2.2 Objectives\n\nLoad and explore a data set with publication quality tables\nDiagnose outliers and missing values in a data set\nPrepare an HTML summary report showcasing properties of a data set"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#required-setup",
    "href": "DiagnosingLikeDataDoctor.html#required-setup",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.3 Required Setup",
    "text": "2.3 Required Setup\nWe first need to prepare our environment with the necessary packages\n\n# Sets the repository to download packages from\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Sets the number of significant figures to two - e.g., 0.01\noptions(digits = 2)\n\n# Required package for quick package downloading and loading \ninstall.packages(\"pacman\")\n\n# Downloads and load required packages\npacman::p_load(dlookr, # Exploratory data analysis\n               formattable, # HTML tables from R outputs\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               missRanger, # To generate NAs\n               tidyverse) # Powerful data wrangling package suite"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#diagnose-your-data",
    "href": "DiagnosingLikeDataDoctor.html#diagnose-your-data",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.5 Diagnose your Data",
    "text": "2.5 Diagnose your Data\n\n# What are the properties of the data\ndataset |>\n  diagnose() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\nmissing_count\n\n\nmissing_percent\n\n\nunique_count\n\n\nunique_rate\n\n\n\n\n\n\nresult_date\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n541\n\n\n0.05893\n\n\n\n\naffil_category\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n4\n\n\n0.00044\n\n\n\n\ntest_type\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n3\n\n\n0.00033\n\n\n\n\ntest_result\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n3\n\n\n0.00033\n\n\n\n\ntest_count\n\n\ninteger\n\n\n0\n\n\n0\n\n\n591\n\n\n0.06438\n\n\n\n\ntest_source\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n2\n\n\n0.00022\n\n\n\n\n\n\n\n\nvariables: name of each variable\ntypes: data type of each variable\nmissing_count: number of missing values\nmissing_percent: percentage of missing values\nunique_count: number of unique values\nunique_rate: rate of unique value - unique_count / number of observations"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#summary-statistics-of-your-data",
    "href": "DiagnosingLikeDataDoctor.html#summary-statistics-of-your-data",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.6 Summary Statistics of your Data",
    "text": "2.6 Summary Statistics of your Data\n\n2.6.1 Numerical Variables\n\n# Summary statistics of our numerical columns\ndataset |>\n  diagnose_numeric() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\nmin\n\n\nQ1\n\n\nmean\n\n\nmedian\n\n\nQ3\n\n\nmax\n\n\nzero\n\n\nminus\n\n\noutlier\n\n\n\n\n\n\ntest_count\n\n\n0\n\n\n0\n\n\n47\n\n\n2\n\n\n16\n\n\n1472\n\n\n2777\n\n\n0\n\n\n1721\n\n\n\n\n\n\n\n\nmin: minimum value\nQ1: 1/4 quartile, 25th percentile\nmean: arithmetic mean (average value)\nmedian: median, 50th percentile\nQ3: 3/4 quartile, 75th percentile\nmax: maximum value\nzero: number of observations with the value 0\nminus: number of observations with negative numbers\noutlier: number of outliers\n\n\n\n\n2.6.2 Outliers\nValues outside of \\(1.5 * IQR\\)\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\nThere are several numerical variables that have outliers above, let’s see what the data look like with and without them\n\nCreate a table with columns containing outliers\nPlot outliers in a box plot and histogram\n\n\n# Table showing outliers\ndiagnose_outlier(dataset) |>\n  filter(outliers_ratio > 0) |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\noutliers_cnt\n\n\noutliers_ratio\n\n\noutliers_mean\n\n\nwith_mean\n\n\nwithout_mean\n\n\n\n\n\n\ntest_count\n\n\n1721\n\n\n19\n\n\n231\n\n\n47\n\n\n4.3\n\n\n\n\n\n\n\n\noutliers_cnt: number of outliers\noutliers_ratio: ratio of outliers over all values\noutliers_mean: arithmetic mean (average value) of outlier values\nwith_mean: arithmetic mean of all values including outliers\nwithout_mean: arithmetic mean of all values excluding outliers\n\n\n# Selecting desired columns \ndataset |>\n    plot_outlier()\n\n\n\n\n\n\n\n2.6.3 Missing Values (NAs)\n\nTable showing the extent of NAs in columns containing them\nPlot showing the frequency of missing values\n\n\n# Create the NA table\ndataset |>\n  generateNA(p = 0.3) |>\n  plot_na_pareto(only_na = TRUE, plot = FALSE) |>\n  formattable() # Publishable table\n\n\n\n\n\n\nvariable\n\n\nfrequencies\n\n\nratio\n\n\ngrade\n\n\ncumulative\n\n\n\n\n\n\naffil_category\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n17\n\n\n\n\nresult_date\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n33\n\n\n\n\ntest_count\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n50\n\n\n\n\ntest_result\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n67\n\n\n\n\ntest_source\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n83\n\n\n\n\ntest_type\n\n\n2754\n\n\n0.3\n\n\nBad\n\n\n100\n\n\n\n\n\n\n\n\n# Plot the intersect of the columns with the most missing values\n# This means that some combinations of columns have missing values in the same row\ndataset |>\n  generateNA(p = 0.3) |>\n  select(test_type, test_result, test_count) |>\n  plot_na_intersect(only_na = TRUE) \n\n\n\n\n\n\n2.6.4 Categorical Variables\n\n# Diagnose our categorical columns\ndataset |>\n  diagnose_category() |> \n  formattable()\n\n\n\n\n\n\nvariables\n\n\nlevels\n\n\nN\n\n\nfreq\n\n\nratio\n\n\nrank\n\n\n\n\n\n\nresult_date\n\n\n2020-09-17\n\n\n9180\n\n\n26\n\n\n0.283\n\n\n1\n\n\n\n\nresult_date\n\n\n2020-09-23\n\n\n9180\n\n\n26\n\n\n0.283\n\n\n1\n\n\n\n\nresult_date\n\n\n2020-10-01\n\n\n9180\n\n\n26\n\n\n0.283\n\n\n1\n\n\n\n\nresult_date\n\n\n2020-10-08\n\n\n9180\n\n\n26\n\n\n0.283\n\n\n1\n\n\n\n\nresult_date\n\n\n2020-09-01\n\n\n9180\n\n\n25\n\n\n0.272\n\n\n5\n\n\n\n\nresult_date\n\n\n2020-09-16\n\n\n9180\n\n\n25\n\n\n0.272\n\n\n5\n\n\n\n\nresult_date\n\n\n2020-09-24\n\n\n9180\n\n\n25\n\n\n0.272\n\n\n5\n\n\n\n\nresult_date\n\n\n2020-12-09\n\n\n9180\n\n\n25\n\n\n0.272\n\n\n5\n\n\n\n\nresult_date\n\n\n2020-12-15\n\n\n9180\n\n\n25\n\n\n0.272\n\n\n5\n\n\n\n\nresult_date\n\n\n2020-09-04\n\n\n9180\n\n\n24\n\n\n0.261\n\n\n10\n\n\n\n\naffil_category\n\n\nOff-Campus Student\n\n\n9180\n\n\n3368\n\n\n36.688\n\n\n1\n\n\n\n\naffil_category\n\n\nEmployee\n\n\n9180\n\n\n2987\n\n\n32.538\n\n\n2\n\n\n\n\naffil_category\n\n\nOn-Campus Student\n\n\n9180\n\n\n2823\n\n\n30.752\n\n\n3\n\n\n\n\naffil_category\n\n\nOther\n\n\n9180\n\n\n2\n\n\n0.022\n\n\n4\n\n\n\n\ntest_type\n\n\nAntigen\n\n\n9180\n\n\n4624\n\n\n50.370\n\n\n1\n\n\n\n\ntest_type\n\n\nPCR\n\n\n9180\n\n\n4554\n\n\n49.608\n\n\n2\n\n\n\n\ntest_type\n\n\nAntibody\n\n\n9180\n\n\n2\n\n\n0.022\n\n\n3\n\n\n\n\ntest_result\n\n\nNegative\n\n\n9180\n\n\n4575\n\n\n49.837\n\n\n1\n\n\n\n\ntest_result\n\n\nPositive\n\n\n9180\n\n\n4575\n\n\n49.837\n\n\n1\n\n\n\n\ntest_result\n\n\nInconclusive\n\n\n9180\n\n\n30\n\n\n0.327\n\n\n3\n\n\n\n\ntest_source\n\n\nTest All Test Smart\n\n\n9180\n\n\n5078\n\n\n55.316\n\n\n1\n\n\n\n\ntest_source\n\n\nCampus Health\n\n\n9180\n\n\n4102\n\n\n44.684\n\n\n2\n\n\n\n\n\n\n\n\nvariables: category names\nlevels: group names within categories\nN: number of observation\nfreq: number of observation at group level / number of observation at category level\nratio: percentage of observation at group level / number of observation at category level\nrank: rank of the occupancy ratio of levels (order in which the groups are in the category)"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#produce-an-html-summary-of-a-data-set",
    "href": "DiagnosingLikeDataDoctor.html#produce-an-html-summary-of-a-data-set",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.7 Produce an HTML Summary of a Data Set",
    "text": "2.7 Produce an HTML Summary of a Data Set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n#diagnose_web_report(dataset)\n\n\n\n\n\nMerchant, Nirav C, Jim Davis, George H Franks, Chun Ly, Fernando Rios, Todd Wickizer, Gary D Windham, and Michelle Yung. 2022. “University of Arizona Test-Trace-Treat COVID-19 Testing Results.” University of Arizona Research Data Repository. https://doi.org/10.25422/AZU.DATA.14869740.V3."
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html",
    "href": "ExploringLikeDataAdventurer.html",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "",
    "text": "Exploring the normality of numerical columns in a novel data set and producing publication quality tables and reports"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#objectives",
    "href": "ExploringLikeDataAdventurer.html#objectives",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.2 Objectives",
    "text": "3.2 Objectives\n\nUsing summary statistics to better understand individual columns in a data set.\nAssessing data normality in numerical columns.\nProducing a publishable HTML with summary statistics and normality tests for columns within a data set."
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#required-setup",
    "href": "ExploringLikeDataAdventurer.html#required-setup",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.3 Required Setup",
    "text": "3.3 Required Setup\nWe first need to prepare our environment with the necessary packages\n\n# Sets the repository to download packages from\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Sets the number of significant figures to two - e.g., 0.01\noptions(digits = 2)\n\n# Required package for quick package downloading and loading \ninstall.packages(\"pacman\")\n\npacman::p_load(dlookr, # Exploratory data analysis\n               formattable, # HTML tables from R outputs\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               tidyverse) # Powerful data wrangling package suite"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#diagnose-your-data",
    "href": "ExploringLikeDataAdventurer.html#diagnose-your-data",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.5 Diagnose your Data",
    "text": "3.5 Diagnose your Data\n\n# What are the properties of the data\ndataset |>\n  diagnose() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\nmissing_count\n\n\nmissing_percent\n\n\nunique_count\n\n\nunique_rate\n\n\n\n\n\n\nDate\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n147\n\n\n0.2500\n\n\n\n\nGroup\n\n\ncharacter\n\n\n0\n\n\n0\n\n\n4\n\n\n0.0068\n\n\n\n\nSap_Flow\n\n\nnumeric\n\n\n108\n\n\n18\n\n\n481\n\n\n0.8180\n\n\n\n\nTWaterFlux\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n508\n\n\n0.8639\n\n\n\n\npLWP\n\n\nnumeric\n\n\n312\n\n\n53\n\n\n277\n\n\n0.4711\n\n\n\n\nmLWP\n\n\nnumeric\n\n\n280\n\n\n48\n\n\n309\n\n\n0.5255\n\n\n\n\n\n\n\n\nvariables: name of each variable\ntypes: data type of each variable\nmissing_count: number of missing values\nmissing_percent: percentage of missing values\nunique_count: number of unique values\nunique_rate: rate of unique value - unique_count / number of observations\n\n\n\n3.5.1 Box Plot\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\n\n\n3.5.2 Skewness\n\n\n\n(c) Andrey Akinshin\n\n\n\n\n3.5.2.1 NOTE\n\n“Skewness” has multiple definitions. Several underlying equations mey be at play\nSkewness is “designed” for distributions with one peak (unimodal); it’s meaningless for distributions with multiple peaks (multimodal).\nMost default skewness definitions are not robust: a single outlier could completely distort the skewness value.\nWe can’t make conclusions about the locations of the mean and the median based on the skewness sign.\n\n\n\n\n\n3.5.3 Kurtosis\n\n\n\n(c) Andrey Akinshin\n\n\n\nNOTE\n\nThere are multiple definitions of kurtosis - i.e., “kurtosis” and “excess kurtosis,” but there are other definitions of this measure.\nKurtosis may work fine for distributions with one peak (unimodal); it’s meaningless for distributions with multiple peaks (multimodal).\nThe classic definition of kurtosis is not robust: it could be easily spoiled by extreme outliers."
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#describe-your-continuous-data",
    "href": "ExploringLikeDataAdventurer.html#describe-your-continuous-data",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.6 Describe your Continuous Data",
    "text": "3.6 Describe your Continuous Data\n\n# Summary statistics \ndataset |>\n  describe() |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np00\n\n\np01\n\n\np05\n\n\np10\n\n\np20\n\n\np25\n\n\np30\n\n\np40\n\n\np50\n\n\np60\n\n\np70\n\n\np75\n\n\np80\n\n\np90\n\n\np95\n\n\np99\n\n\np100\n\n\n\n\n\n\nSap_Flow\n\n\n480\n\n\n108\n\n\n25.09\n\n\n40.52\n\n\n1.849\n\n\n13.92\n\n\n2.2\n\n\n4.20\n\n\n0.17\n\n\n0.33\n\n\n0.47\n\n\n1.15\n\n\n2.26\n\n\n2.45\n\n\n3.76\n\n\n5.05\n\n\n5.82\n\n\n9.03\n\n\n10.51\n\n\n16.37\n\n\n48.89\n\n\n83.48\n\n\n109.84\n\n\n176.99\n\n\n184.04\n\n\n\n\nTWaterFlux\n\n\n588\n\n\n0\n\n\n11.93\n\n\n19.05\n\n\n0.786\n\n\n6.28\n\n\n2.1\n\n\n3.88\n\n\n0.10\n\n\n0.15\n\n\n0.22\n\n\n0.60\n\n\n1.14\n\n\n1.29\n\n\n1.70\n\n\n2.31\n\n\n3.00\n\n\n4.20\n\n\n5.21\n\n\n7.58\n\n\n23.37\n\n\n43.14\n\n\n51.81\n\n\n80.87\n\n\n96.01\n\n\n\n\npLWP\n\n\n276\n\n\n312\n\n\n-0.61\n\n\n0.23\n\n\n0.014\n\n\n0.26\n\n\n-1.1\n\n\n1.77\n\n\n-1.43\n\n\n-1.32\n\n\n-1.07\n\n\n-0.88\n\n\n-0.73\n\n\n-0.71\n\n\n-0.68\n\n\n-0.62\n\n\n-0.59\n\n\n-0.55\n\n\n-0.49\n\n\n-0.45\n\n\n-0.41\n\n\n-0.35\n\n\n-0.30\n\n\n-0.24\n\n\n-0.21\n\n\n\n\nmLWP\n\n\n308\n\n\n280\n\n\n-1.03\n\n\n0.30\n\n\n0.017\n\n\n0.42\n\n\n-0.8\n\n\n-0.18\n\n\n-1.81\n\n\n-1.79\n\n\n-1.62\n\n\n-1.46\n\n\n-1.32\n\n\n-1.23\n\n\n-1.13\n\n\n-1.04\n\n\n-0.95\n\n\n-0.90\n\n\n-0.84\n\n\n-0.81\n\n\n-0.76\n\n\n-0.71\n\n\n-0.67\n\n\n-0.59\n\n\n-0.55\n\n\n\n\n\n\n\n\ndescribes_variables: name of the column being described\nn: number of observations excluding missing values\nna: number of missing values\nmean: arithmetic average\nsd: standard deviation\nse_mean: standard error mean. sd/sqrt(n)\nIQR: interquartile range (Q3-Q1)\nskewness: skewness\nkurtosis: kurtosis\np25: Q1. 25% percentile\np50: median. 50% percentile\np75: Q3. 75% percentile\np01, p05, p10, p20, p30: 1%, 5%, 20%, 30% percentiles\np40, p60, p70, p80: 40%, 60%, 70%, 80% percentiles\np90, p95, p99, p100: 90%, 95%, 99%, 100% percentiles\n\n\n\n3.6.1 Describe your Continuous Data: Refined\nThe above is pretty overwhelming, and most people don’t care about percentiles outside of Q1, Q3, and the median (Q2).\n\n# Summary statistics, selecting the desired ones\ndataset |>\n  describe() |>\n  select(described_variables, n, na, mean, sd, se_mean, IQR, skewness, kurtosis, p25, p50, p75) |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np25\n\n\np50\n\n\np75\n\n\n\n\n\n\nSap_Flow\n\n\n480\n\n\n108\n\n\n25.09\n\n\n40.52\n\n\n1.849\n\n\n13.92\n\n\n2.2\n\n\n4.20\n\n\n2.45\n\n\n5.82\n\n\n16.37\n\n\n\n\nTWaterFlux\n\n\n588\n\n\n0\n\n\n11.93\n\n\n19.05\n\n\n0.786\n\n\n6.28\n\n\n2.1\n\n\n3.88\n\n\n1.29\n\n\n3.00\n\n\n7.58\n\n\n\n\npLWP\n\n\n276\n\n\n312\n\n\n-0.61\n\n\n0.23\n\n\n0.014\n\n\n0.26\n\n\n-1.1\n\n\n1.77\n\n\n-0.71\n\n\n-0.59\n\n\n-0.45\n\n\n\n\nmLWP\n\n\n308\n\n\n280\n\n\n-1.03\n\n\n0.30\n\n\n0.017\n\n\n0.42\n\n\n-0.8\n\n\n-0.18\n\n\n-1.23\n\n\n-0.95\n\n\n-0.81"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#describe-categorical-variables",
    "href": "ExploringLikeDataAdventurer.html#describe-categorical-variables",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.7 Describe Categorical Variables",
    "text": "3.7 Describe Categorical Variables\n\ndataset |>\n  diagnose_category() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\nlevels\n\n\nN\n\n\nfreq\n\n\nratio\n\n\nrank\n\n\n\n\n\n\nDate\n\n\n1/1/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/10/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/11/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/12/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/13/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/14/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/15/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/16/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/17/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nDate\n\n\n1/18/20\n\n\n588\n\n\n4\n\n\n0.68\n\n\n1\n\n\n\n\nGroup\n\n\nDrought-sensitive canopy\n\n\n588\n\n\n147\n\n\n25.00\n\n\n1\n\n\n\n\nGroup\n\n\nDrought-sensitive understory\n\n\n588\n\n\n147\n\n\n25.00\n\n\n1\n\n\n\n\nGroup\n\n\nDrought-tolerant canopy\n\n\n588\n\n\n147\n\n\n25.00\n\n\n1\n\n\n\n\nGroup\n\n\nDrought-tolerant understory\n\n\n588\n\n\n147\n\n\n25.00\n\n\n1\n\n\n\n\n\n\n\n\nvariables: category names\nlevels: group names within categories\nN: number of observation\nfreq: number of observation at group level / number of observation at category level\nratio: percentage of observation at group level / number of observation at category level\nrank: rank of the occupancy ratio of levels (order in which the groups are in the category)\n\n\n\n3.7.1 Group Descriptive Statistics\n\ndataset |>\n  group_by(Group) |>\n  describe() |>\n  select(described_variables, Group, n, na, mean, sd, se_mean, IQR, skewness, kurtosis, p25, p50, p75) |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nGroup\n\n\nn\n\n\nna\n\n\nmean\n\n\nsd\n\n\nse_mean\n\n\nIQR\n\n\nskewness\n\n\nkurtosis\n\n\np25\n\n\np50\n\n\np75\n\n\n\n\n\n\nmLWP\n\n\nDrought-sensitive canopy\n\n\n77\n\n\n70\n\n\n-1.32\n\n\n0.298\n\n\n0.034\n\n\n0.41\n\n\n0.3178\n\n\n-0.691\n\n\n-1.53\n\n\n-1.35\n\n\n-1.11\n\n\n\n\nmLWP\n\n\nDrought-sensitive understory\n\n\n77\n\n\n70\n\n\n-1.10\n\n\n0.264\n\n\n0.030\n\n\n0.43\n\n\n-0.3411\n\n\n-0.313\n\n\n-1.34\n\n\n-1.05\n\n\n-0.91\n\n\n\n\nmLWP\n\n\nDrought-tolerant canopy\n\n\n77\n\n\n70\n\n\n-0.89\n\n\n0.092\n\n\n0.010\n\n\n0.12\n\n\n-0.2608\n\n\n-0.402\n\n\n-0.95\n\n\n-0.89\n\n\n-0.83\n\n\n\n\nmLWP\n\n\nDrought-tolerant understory\n\n\n77\n\n\n70\n\n\n-0.81\n\n\n0.171\n\n\n0.019\n\n\n0.21\n\n\n-0.9539\n\n\n-0.412\n\n\n-0.91\n\n\n-0.74\n\n\n-0.70\n\n\n\n\npLWP\n\n\nDrought-sensitive canopy\n\n\n69\n\n\n78\n\n\n-0.67\n\n\n0.246\n\n\n0.030\n\n\n0.32\n\n\n-0.3510\n\n\n-0.274\n\n\n-0.79\n\n\n-0.71\n\n\n-0.47\n\n\n\n\npLWP\n\n\nDrought-sensitive understory\n\n\n69\n\n\n78\n\n\n-0.70\n\n\n0.284\n\n\n0.034\n\n\n0.28\n\n\n-1.1510\n\n\n0.480\n\n\n-0.80\n\n\n-0.59\n\n\n-0.52\n\n\n\n\npLWP\n\n\nDrought-tolerant canopy\n\n\n69\n\n\n78\n\n\n-0.63\n\n\n0.096\n\n\n0.012\n\n\n0.14\n\n\n-0.4644\n\n\n-0.592\n\n\n-0.71\n\n\n-0.60\n\n\n-0.57\n\n\n\n\npLWP\n\n\nDrought-tolerant understory\n\n\n69\n\n\n78\n\n\n-0.44\n\n\n0.132\n\n\n0.016\n\n\n0.16\n\n\n-0.4333\n\n\n-0.432\n\n\n-0.52\n\n\n-0.41\n\n\n-0.36\n\n\n\n\nSap_Flow\n\n\nDrought-sensitive canopy\n\n\n120\n\n\n27\n\n\n85.27\n\n\n41.314\n\n\n3.771\n\n\n40.09\n\n\n1.0493\n\n\n0.150\n\n\n53.98\n\n\n76.72\n\n\n94.07\n\n\n\n\nSap_Flow\n\n\nDrought-sensitive understory\n\n\n120\n\n\n27\n\n\n1.45\n\n\n0.804\n\n\n0.073\n\n\n1.66\n\n\n-0.2242\n\n\n-1.635\n\n\n0.53\n\n\n1.67\n\n\n2.19\n\n\n\n\nSap_Flow\n\n\nDrought-tolerant canopy\n\n\n120\n\n\n27\n\n\n9.07\n\n\n1.396\n\n\n0.127\n\n\n2.28\n\n\n-0.6344\n\n\n-0.695\n\n\n8.12\n\n\n9.29\n\n\n10.40\n\n\n\n\nSap_Flow\n\n\nDrought-tolerant understory\n\n\n120\n\n\n27\n\n\n4.57\n\n\n0.902\n\n\n0.082\n\n\n1.09\n\n\n-0.9141\n\n\n-0.077\n\n\n4.05\n\n\n4.94\n\n\n5.14\n\n\n\n\nTWaterFlux\n\n\nDrought-sensitive canopy\n\n\n147\n\n\n0\n\n\n40.40\n\n\n19.028\n\n\n1.569\n\n\n24.88\n\n\n0.9210\n\n\n0.509\n\n\n25.22\n\n\n38.63\n\n\n50.10\n\n\n\n\nTWaterFlux\n\n\nDrought-sensitive understory\n\n\n147\n\n\n0\n\n\n0.75\n\n\n0.429\n\n\n0.035\n\n\n0.84\n\n\n0.0105\n\n\n-1.188\n\n\n0.27\n\n\n0.82\n\n\n1.11\n\n\n\n\nTWaterFlux\n\n\nDrought-tolerant canopy\n\n\n147\n\n\n0\n\n\n4.36\n\n\n0.940\n\n\n0.078\n\n\n1.51\n\n\n-0.3548\n\n\n-0.940\n\n\n3.60\n\n\n4.46\n\n\n5.11\n\n\n\n\nTWaterFlux\n\n\nDrought-tolerant understory\n\n\n147\n\n\n0\n\n\n2.19\n\n\n0.598\n\n\n0.049\n\n\n0.95\n\n\n-0.0087\n\n\n-0.779\n\n\n1.74\n\n\n2.20\n\n\n2.69"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#testing-normality",
    "href": "ExploringLikeDataAdventurer.html#testing-normality",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.8 Testing Normality",
    "text": "3.8 Testing Normality\n\nShapiro-Wilk test & Q-Q plots\nTesting overall normality of two columns\nTesting normality of groups\n\n\n\n3.8.1 Normality of Columns\n\n\n3.8.1.1 Shapiro-Wilk Test\nShapiro-Wilk test looks at whether a target distribution is sample form a normal distribution\n\ndataset |>\n  normality() |>\n  formattable()\n\n\n\n\n\n\nvars\n\n\nstatistic\n\n\np_value\n\n\nsample\n\n\n\n\n\n\nSap_Flow\n\n\n0.63\n\n\n7.4e-31\n\n\n588\n\n\n\n\nTWaterFlux\n\n\n0.64\n\n\n2.2e-33\n\n\n588\n\n\n\n\npLWP\n\n\n0.93\n\n\n3.4e-10\n\n\n588\n\n\n\n\nmLWP\n\n\n0.93\n\n\n7.0e-11\n\n\n588\n\n\n\n\n\n\n\n\n\n\n3.8.1.2 Q-Q Plots\nPlots of the quartiles of a target data set and plot it against predicted quartiles from a normal distribution\n\ndataset |>\nplot_normality()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.8.2 Normality within Groups\nLooking within Age_group at the subgroup normality\n\n3.8.2.1 Shapiro-Wilk Test\n\ndataset |>\n  group_by(Group) |>\n  select(Sap_Flow, TWaterFlux) |>\n  normality() |>\n  formattable()\n\n\n\n\n\n\nvariable\n\n\nGroup\n\n\nstatistic\n\n\np_value\n\n\nsample\n\n\n\n\n\n\nSap_Flow\n\n\nDrought-sensitive canopy\n\n\n0.87\n\n\n9.8e-09\n\n\n147\n\n\n\n\nSap_Flow\n\n\nDrought-sensitive understory\n\n\n0.86\n\n\n2.2e-09\n\n\n147\n\n\n\n\nSap_Flow\n\n\nDrought-tolerant canopy\n\n\n0.91\n\n\n8.3e-07\n\n\n147\n\n\n\n\nSap_Flow\n\n\nDrought-tolerant understory\n\n\n0.90\n\n\n2.2e-07\n\n\n147\n\n\n\n\nTWaterFlux\n\n\nDrought-sensitive canopy\n\n\n0.93\n\n\n1.1e-06\n\n\n147\n\n\n\n\nTWaterFlux\n\n\nDrought-sensitive understory\n\n\n0.93\n\n\n1.3e-06\n\n\n147\n\n\n\n\nTWaterFlux\n\n\nDrought-tolerant canopy\n\n\n0.96\n\n\n1.3e-04\n\n\n147\n\n\n\n\nTWaterFlux\n\n\nDrought-tolerant understory\n\n\n0.98\n\n\n4.4e-02\n\n\n147\n\n\n\n\n\n\n\n\n\n3.8.2.2 Q-Q Plots\n\ndataset |>\ngroup_by(Group) |>\n  select(Sap_Flow, TWaterFlux) |>\n  plot_normality()"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#produce-an-html-normality-summary-of-a-data-set",
    "href": "ExploringLikeDataAdventurer.html#produce-an-html-normality-summary-of-a-data-set",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.9 Produce an HTML normality summary of a data set",
    "text": "3.9 Produce an HTML normality summary of a data set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n#eda_web_report(dataset)\n\n\n\n\n\nMeredith, Laura, S. Nemiah Ladd, and Christiane Werner. 2021. “Data for \"Ecosystem Fluxes During Drought and Recovery in an Experimental Forest\".” University of Arizona Research Data Repository. https://doi.org/10.25422/AZU.DATA.14632593.V1."
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#load-and-examine-a-data-set",
    "href": "ExploringLikeDataAdventurer.html#load-and-examine-a-data-set",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.4 Load and Examine a Data Set",
    "text": "3.4 Load and Examine a Data Set\nWe will be using open source data from UArizona researchers that investigates the effects of climate change on canopy trees. (Meredith, Ladd, and Werner 2021)\n\n# Let's load a data set from the canopy tree data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"Data_Fig2_Repo.csv\")) \n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nDate\n\n\nGroup\n\n\nSap_Flow\n\n\nTWaterFlux\n\n\npLWP\n\n\nmLWP\n\n\n\n\n\n\n10/4/19\n\n\nDrought-sensitive canopy\n\n\n184.0\n\n\n82.2\n\n\n-0.26\n\n\n-0.68\n\n\n\n\n10/4/19\n\n\nDrought-sensitive understory\n\n\n2.5\n\n\n1.3\n\n\n-0.30\n\n\n-0.76\n\n\n\n\n10/4/19\n\n\nDrought-tolerant canopy\n\n\n10.6\n\n\n4.4\n\n\n-0.44\n\n\n-0.72\n\n\n\n\n10/4/19\n\n\nDrought-tolerant understory\n\n\n4.4\n\n\n2.1\n\n\n-0.21\n\n\n-0.70\n\n\n\n\n10/5/19\n\n\nDrought-sensitive canopy\n\n\n182.9\n\n\n95.9\n\n\n-0.28\n\n\n-0.71\n\n\n\n\n10/5/19\n\n\nDrought-sensitive understory\n\n\n2.5\n\n\n1.2\n\n\n-0.32\n\n\n-0.79"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#load-and-examine-a-data-set",
    "href": "DiagnosingLikeDataDoctor.html#load-and-examine-a-data-set",
    "title": "2  Exploratory Data Analysis in R - Diagnosing like a Data Doctor",
    "section": "2.4 Load and Examine a Data Set",
    "text": "2.4 Load and Examine a Data Set\n\nLoad data and view\nExamine columns and data types\nDefine box plots\nDescribe meta data\n\nWe will be using open source data from UArizona researchers for Test, Trace, Treat (T3) efforts offers two clinical diagnostic tests (Antigen, RT-PCR) to determine whether an individual is currently infected with the COVID-19 virus. (Merchant et al. 2022)\n\n# Let's load a data set from the COVID-19 daily testing data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"daily_summary.csv\")) \n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nresult_date\n\n\naffil_category\n\n\ntest_type\n\n\ntest_result\n\n\ntest_count\n\n\ntest_source\n\n\n\n\n\n\n2020-08-04\n\n\nEmployee\n\n\nAntigen\n\n\nNegative\n\n\n5\n\n\nCampus Health\n\n\n\n\n2020-08-04\n\n\nEmployee\n\n\nAntigen\n\n\nPositive\n\n\n0\n\n\nCampus Health\n\n\n\n\n2020-08-04\n\n\nEmployee\n\n\nAntigen\n\n\nNegative\n\n\n1\n\n\nTest All Test Smart\n\n\n\n\n2020-08-04\n\n\nEmployee\n\n\nAntigen\n\n\nPositive\n\n\n0\n\n\nTest All Test Smart\n\n\n\n\n2020-08-04\n\n\nOff-Campus Student\n\n\nAntigen\n\n\nNegative\n\n\n9\n\n\nCampus Health\n\n\n\n\n2020-08-04\n\n\nOff-Campus Student\n\n\nAntigen\n\n\nPositive\n\n\n1\n\n\nCampus Health"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#objectives",
    "href": "TransformingLikeDataTrans.html#objectives",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.2 Objectives",
    "text": "4.2 Objectives\n\nLoad and explore a data set with publication quality tables\nQuickly diagnose non-normality in data\nData transformation\nPrepare an HTML summary report showcasing data transformations"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#required-setup",
    "href": "TransformingLikeDataTrans.html#required-setup",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.3 Required Setup",
    "text": "4.3 Required Setup\nWe first need to prepare our environment with the necessary packages\n\n# Sets the repository to download packages from\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Sets the number of significant figures to two - e.g., 0.01\noptions(digits = 2)\n\n# Required package for quick package downloading and loading \ninstall.packages(\"pacman\")\n\n# Downloads and load required packages\npacman::p_load(dlookr, # Exploratory data analysis\n               forecast, # Needed for Box-Cox transformations\n               formattable, # HTML tables from R outputs\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               missRanger, # To generate NAs\n               tidyverse) # Powerful data wrangling package suite"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#load-and-examine-a-data-set",
    "href": "TransformingLikeDataTrans.html#load-and-examine-a-data-set",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.4 Load and Examine a Data Set",
    "text": "4.4 Load and Examine a Data Set\n\nLoad data and view\nExamine columns and data types\nExamine data normality\nDescribe properties of data\n\n\n# Let's load a data set from the diabetes data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"diabetes.csv\")) |>\n  # Add a categorical group\n  mutate(Age_group = ifelse(Age >= 21 & Age <= 30, \"Young\", \n                            ifelse(Age > 30 & Age <= 50, \"Middle\", \n                                   \"Elderly\")),\n         Age_group = fct_rev(Age_group))\n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28\n\n\n0.17\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n26\n\n\n0.20\n\n\n30\n\n\n0\n\n\nYoung\n\n\n\n\n\n\n\n\n4.4.1 Data Normality\nNormal distributions (bell curves) are a common data assumptions for many hypothesis testing statistics, in particular parametric statistics. Deviations from normality can either strongly skew the results or reduce the power to detect a significant statistical difference.\nHere are the distribution properties to know and consider:\n\nThe mean, median, and mode are the same value.\nDistribution symmetry at the mean.\nNormal distributions can be described by the mean and standard deviation.\n\nHere’s an example using the Glucose column in our dataset\n\n# Function for data mode\ngetmode <- function(v) {\n   uniqv <- unique(v)\n   uniqv[which.max(tabulate(match(v, uniqv)))]\n}\n\ndataset |> \n  ggplot(aes(x = BMI)) +\n  geom_histogram(fill = \"#4E84C4\", size = 2, bins = 40) +\n  geom_point(aes(y = 30, x = mean(BMI)), size = 5) +\n  geom_point(aes(y = 30, x = median(BMI)), size = 5) +\n  geom_point(aes(y = 30, x = getmode(BMI)), size = 5) +\n  geom_vline(aes(xintercept = mean(BMI) - sd(BMI)), size = 1.5, linetype = \"dashed\") + \n  geom_vline(aes(xintercept = mean(BMI) + sd(BMI)), size = 1.5, linetype = \"dashed\") +\n  geom_segment(aes(y = 30, yend = 30, x = mean(BMI) - sd(BMI), xend = mean(BMI) + sd(BMI)), size = 1.5) +\n  geom_segment(aes(y = 32, yend = 45, x = mean(BMI) + 1.5, xend = 50)) +\n  geom_segment(aes(y = 30, yend = 30, x = mean(BMI) + sd(BMI) + 1, xend = 50)) +\n  annotate(geom = \"text\", x = 50.5, y = 45, label = \"Mean, \\nMedian, \\nMode = 32\", size = 5, hjust = 0) +\n  annotate(geom = \"text\", x = 50.5, y = 30, label = \"SD = 7.9\", size = 5, hjust = 0) +\n  theme(axis.title.y = element_blank()) \n\n\n\n\n\n\n4.4.2 Describing Properties of our Data (Refined)\n\n4.4.2.1 Skewness\nThe symmetry of the distribution\nSee Introduction 1.3.3 for more information about these values\n\ndataset |>\n  select(Glucose, Insulin, BMI, SkinThickness) |>\n  describe() |>\n  select(described_variables, skewness) |>\n  formattable()\n\n\n\n\n\n\ndescribed_variables\n\n\nskewness\n\n\n\n\n\n\nGlucose\n\n\n0.17\n\n\n\n\nInsulin\n\n\n2.27\n\n\n\n\nBMI\n\n\n-0.43\n\n\n\n\nSkinThickness\n\n\n0.11\n\n\n\n\n\n\n\nNote that we will remove the other percentiles to produce a cleaner output\n\ndescribes_variables: name of the column being described\nskewness: skewness"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#testing-normality-accelerated",
    "href": "TransformingLikeDataTrans.html#testing-normality-accelerated",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.5 Testing Normality (Accelerated)",
    "text": "4.5 Testing Normality (Accelerated)\n\nQ-Q plots\nTesting overall normality of two columns\nTesting normality of groups\n\nNote that you can also use normality() to run Shapiro-Wilk tests, but since this test is not viable at N < 20, I recommend just skipping to Q-Q plots.\n\n4.5.0.1 Q-Q Plots\nPlots of the quartiles of a target data set and plot it against predicted quartiles from a normal distribution.\nNotably, plot_normality() will show you the Logaritmic and Skewed transformations (more below)\n\ndataset |>\nplot_normality(Glucose, Insulin, Age)"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#normality-within-groups",
    "href": "TransformingLikeDataTrans.html#normality-within-groups",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.6 Normality within Groups",
    "text": "4.6 Normality within Groups\nLooking within Age_group at the subgroup normality\n\n4.6.0.1 Q-Q Plots\n\ndataset %>%\n  group_by(Age_group) %>%\n  select(Glucose, Insulin) %>%\n  plot_normality()"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#transforming-data",
    "href": "TransformingLikeDataTrans.html#transforming-data",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.7 Transforming Data",
    "text": "4.7 Transforming Data\nYour data could be more easily interpreted with a transformation, since not all relationships in nature follow a linear relationship - i.e., many biological phenomena follow a power law (or logarithmic curve), where they do not scale linearly.\nWe will try to transform the Insulin column with through several approaches and discuss the pros and cons of each. First however, we will remove 0 values, because Insulin values are impossible…\n\nInsMod <- dataset |>\n  filter(Insulin > 0)\n\n\n4.7.1 Square-root, Cube-root, and Logarithmic Transformations\nResolving Skewness using transform().\n“sqrt”: square-root transformation. \\(\\sqrt x\\) (moderate skew)\n“log”: log transformation. \\(log(x)\\) (greater skew)\n“log+1”: log transformation. \\(log(x + 1)\\). Used for values that contain 0.\n“1/x”: inverse transformation. \\(1/x\\) (severe skew)\n“x^2”: squared transformation. \\(x^2\\)\n“x^3”: cubed transformation. \\(x^3\\)\nWe will compare sqrt, log+1, and 1/x (inverse) transformations. Note that you would have to add a constant to use the log transformation, so it is easier to use the log+1 instead. You however need to add a constant to both the sqrt and 1/x transformations because they don’t include zeros and will otherwise skew the results.\n\n4.7.1.1 Square-root Transformation\n\nsqrtIns <- transform(InsMod$Insulin, method = \"sqrt\") \n\nsummary(sqrtIns)\n\n* Resolving Skewness with sqrt\n\n* Information of Transformation (before vs after)\n         Original Transformation\nn           394.0         394.00\nna            0.0           0.00\nmean        155.5          11.75\nsd          118.8           4.17\nse_mean       6.0           0.21\nIQR         113.8           5.05\nskewness      2.2           1.01\nkurtosis      6.4           1.46\np00          14.0           3.74\np01          18.0           4.24\np05          41.7           6.45\np10          50.3           7.09\np20          69.2           8.32\np25          76.2           8.73\np30          87.9           9.38\np40         105.0          10.25\np50         125.0          11.18\np60         145.8          12.07\np70         176.0          13.27\np75         190.0          13.78\np80         210.0          14.49\np90         292.4          17.10\np95         395.5          19.89\np99         580.5          24.09\np100        846.0          29.09\n\n\n\nsqrtIns |>\n  plot()\n\n\n\n\n\n\n4.7.1.2 Logarithmic (+1) Transformation\n\nLog1Ins <- transform(InsMod$Insulin, method = \"log+1\") \n\nsummary(Log1Ins)\n\n* Resolving Skewness with log+1\n\n* Information of Transformation (before vs after)\n         Original Transformation\nn           394.0        394.000\nna            0.0          0.000\nmean        155.5          4.818\nsd          118.8          0.691\nse_mean       6.0          0.035\nIQR         113.8          0.905\nskewness      2.2         -0.088\nkurtosis      6.4          0.237\np00          14.0          2.708\np01          18.0          2.944\np05          41.7          3.753\np10          50.3          3.938\np20          69.2          4.251\np25          76.2          4.347\np30          87.9          4.488\np40         105.0          4.663\np50         125.0          4.836\np60         145.8          4.989\np70         176.0          5.176\np75         190.0          5.252\np80         210.0          5.352\np90         292.4          5.682\np95         395.5          5.983\np99         580.5          6.366\np100        846.0          6.742\n\n\n\nLog1Ins |>\n  plot()\n\n\n\n\n\n\n4.7.1.3 Inverse Transformation\n\nInvIns <- transform(InsMod$Insulin, method = \"1/x\") \n\nsummary(InvIns)\n\n* Resolving Skewness with 1/x\n\n* Information of Transformation (before vs after)\n         Original Transformation\nn           394.0        3.9e+02\nna            0.0        0.0e+00\nmean        155.5        1.1e-02\nsd          118.8        9.0e-03\nse_mean       6.0        4.6e-04\nIQR         113.8        7.9e-03\nskewness      2.2        3.2e+00\nkurtosis      6.4        1.5e+01\np00          14.0        1.2e-03\np01          18.0        1.7e-03\np05          41.7        2.5e-03\np10          50.3        3.4e-03\np20          69.2        4.8e-03\np25          76.2        5.3e-03\np30          87.9        5.7e-03\np40         105.0        6.9e-03\np50         125.0        8.0e-03\np60         145.8        9.5e-03\np70         176.0        1.1e-02\np75         190.0        1.3e-02\np80         210.0        1.4e-02\np90         292.4        2.0e-02\np95         395.5        2.4e-02\np99         580.5        5.6e-02\np100        846.0        7.1e-02\n\n\n\nInvIns |>\n  plot()\n\n\n\n\n\n\n\n4.7.2 Box-cox Transformation\nThere are several transformations, each with it’s own “criteria”, and they don’t always fix extremely skewed data. Instead, you can just choose the Box-Cox transformation which searches for the the best lambda value that maximizes the log-likelihood (basically, what power transformation is best). The benefit is that you should have normally distributed data after, but the power relationship might be pretty abstract (i.e., what would a transformation of x^0.12 be interpreted as in your system?..)\n\nBoxCoxIns <- transform(InsMod$Insulin, method = \"Box-Cox\") \n\nsummary(BoxCoxIns)\n\n* Resolving Skewness with Box-Cox\n\n* Information of Transformation (before vs after)\n         Original Transformation\nn           394.0        394.000\nna            0.0          0.000\nmean        155.5          3.011\nsd          118.8          0.262\nse_mean       6.0          0.013\nIQR         113.8          0.335\nskewness      2.2         -0.630\nkurtosis      6.4          1.003\np00          14.0          2.027\np01          18.0          2.168\np05          41.7          2.588\np10          50.3          2.673\np20          69.2          2.808\np25          76.2          2.848\np30          87.9          2.904\np40         105.0          2.973\np50         125.0          3.037\np60         145.8          3.092\np70         176.0          3.157\np75         190.0          3.183\np80         210.0          3.216\np90         292.4          3.320\np95         395.5          3.409\np99         580.5          3.515\np100        846.0          3.610\n\n\n\nBoxCoxIns |>\n  plot()"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#produce-an-html-summary-of-a-data-set",
    "href": "TransformingLikeDataTrans.html#produce-an-html-summary-of-a-data-set",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.8 Produce an HTML Summary of a Data Set",
    "text": "4.8 Produce an HTML Summary of a Data Set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n# transformation_web_report(dataset)"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html",
    "href": "ImputatingLikeDataScientist.html",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "",
    "text": "Exploring, visualizing, and imputing outliers and missing values (NAs) in a novel data set and produce publication quality graphs and tables"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#objectives",
    "href": "ImputatingLikeDataScientist.html#objectives",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.2 Objectives",
    "text": "5.2 Objectives\n\nLoad and explore a data set with publication quality tables\nThoroughly diagnose outliers and missing values\nImpute outliers and missing values"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#required-setup",
    "href": "ImputatingLikeDataScientist.html#required-setup",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.3 Required Setup",
    "text": "5.3 Required Setup\nWe first need to prepare our environment with the necessary packages and set a global theme for publishable plots in ggplot()\n\n# Sets the repository to download packages from\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Sets the number of significant figures to two - e.g., 0.01\noptions(digits = 2)\n\n# Required package for quick package downloading and loading \ninstall.packages(\"pacman\")\n\npacman::p_load(colorblindr, # Colorblind friendly pallettes\n               cluster, # K cluster analyses\n               dlookr, # Exploratory data analysis\n               formattable, # HTML tables from R outputs\n               ggfortify, # Plotting tools for stats\n               ggpubr, # Publishable ggplots\n               here, # Standardizes paths to data\n               kableExtra, # Alternative to formattable\n               knitr, # Needed to write HTML reports\n               missRanger, # To generate NAs\n               plotly, # Visualization package\n               rattle, # Decision tree visualization\n               rpart, # rpart algorithm\n               tidyverse, # Powerful data wrangling package suite\n               visdat) # Another EDA visualization package\n\n# Set global ggplot() theme\n# Theme pub_clean() from the ggpubr package with base text size = 16\ntheme_set(theme_pubclean(base_size = 16)) \n# All axes titles to their respective far right sides\ntheme_update(axis.title = element_text(hjust = 1))\n# Remove axes ticks\ntheme_update(axis.ticks = element_blank()) \n# Remove legend key\ntheme_update(legend.key = element_blank())"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#diagnose-your-data",
    "href": "ImputatingLikeDataScientist.html#diagnose-your-data",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.5 Diagnose your Data",
    "text": "5.5 Diagnose your Data\n\n# What are the properties of the data\ndataset |>\n  diagnose() |>\n  formattable()\n\n\n\n\n\n\nvariables\n\n\ntypes\n\n\nmissing_count\n\n\nmissing_percent\n\n\nunique_count\n\n\nunique_rate\n\n\n\n\n\n\nPregnancies\n\n\ninteger\n\n\n0\n\n\n0\n\n\n17\n\n\n0.0221\n\n\n\n\nGlucose\n\n\ninteger\n\n\n0\n\n\n0\n\n\n136\n\n\n0.1771\n\n\n\n\nBloodPressure\n\n\ninteger\n\n\n0\n\n\n0\n\n\n47\n\n\n0.0612\n\n\n\n\nSkinThickness\n\n\ninteger\n\n\n0\n\n\n0\n\n\n51\n\n\n0.0664\n\n\n\n\nInsulin\n\n\ninteger\n\n\n0\n\n\n0\n\n\n186\n\n\n0.2422\n\n\n\n\nBMI\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n248\n\n\n0.3229\n\n\n\n\nDiabetesPedigreeFunction\n\n\nnumeric\n\n\n0\n\n\n0\n\n\n517\n\n\n0.6732\n\n\n\n\nAge\n\n\ninteger\n\n\n0\n\n\n0\n\n\n52\n\n\n0.0677\n\n\n\n\nOutcome\n\n\ninteger\n\n\n0\n\n\n0\n\n\n2\n\n\n0.0026\n\n\n\n\nAge_group\n\n\nfactor\n\n\n0\n\n\n0\n\n\n3\n\n\n0.0039\n\n\n\n\n\n\n\n\nvariables: name of each variable\ntypes: data type of each variable\nmissing_count: number of missing values\nmissing_percent: percentage of missing values\nunique_count: number of unique values\nunique_rate: rate of unique value - unique_count / number of observations"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#diagnose-outliers",
    "href": "ImputatingLikeDataScientist.html#diagnose-outliers",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.6 Diagnose Outliers",
    "text": "5.6 Diagnose Outliers\nThere are several numerical variables that have outliers above, let’s see what the data look like with and without them\n\nCreate a table with columns containing outliers\nPlot outliers in a box plot and histogram\n\n\n# Table showing outliers\ndataset |>\n  diagnose_outlier() |>\n  filter(outliers_ratio > 0) |>  \n  mutate(rate = outliers_mean / with_mean) |>\n  arrange(desc(rate)) |> \n  select(-outliers_cnt)\n\n                 variables outliers_ratio outliers_mean with_mean without_mean\n1                  Insulin           4.43         457.0     79.80        62.33\n2            SkinThickness           0.13          99.0     20.54        20.43\n3              Pregnancies           0.52          15.0      3.85         3.79\n4 DiabetesPedigreeFunction           3.78           1.5      0.47         0.43\n5                      Age           1.17          70.0     33.24        32.81\n6                      BMI           2.47          23.7     31.99        32.20\n7            BloodPressure           5.86          19.2     69.11        72.21\n8                  Glucose           0.65           0.0    120.89       121.69\n  rate\n1 5.73\n2 4.82\n3 3.90\n4 3.27\n5 2.11\n6 0.74\n7 0.28\n8 0.00\n\n\n\n# Boxplots and histograms of data with and without outliers\ndataset |>\n  select(find_outliers(dataset)) |>\n           plot_outlier()"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#basic-exploration-of-missing-values-nas",
    "href": "ImputatingLikeDataScientist.html#basic-exploration-of-missing-values-nas",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.7 Basic Exploration of Missing Values (NAs)",
    "text": "5.7 Basic Exploration of Missing Values (NAs)\n\nTable showing the extent of NAs in columns containing them\n\n\n# Randomly generate NAs for 30\nna.dataset <- dataset |>\n  generateNA(p = 0.3)\n\n# First six rows\nna.dataset |>\nhead() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\nNA\n\n\nNA\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\nNA\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\nNA\n\n\nMiddle\n\n\n\n\n8\n\n\nNA\n\n\nNA\n\n\n0\n\n\nNA\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\nNA\n\n\nNA\n\n\n66\n\n\n23\n\n\nNA\n\n\n28\n\n\n0.17\n\n\nNA\n\n\nNA\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\nNA\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\nNA\n\n\n74\n\n\nNA\n\n\n0\n\n\nNA\n\n\n0.20\n\n\n30\n\n\n0\n\n\nYoung\n\n\n\n\n\n\n# Create the NA table\nna.dataset |>\n  plot_na_pareto(only_na = TRUE, plot = FALSE) |>\n  formattable() # Publishable table\n\n\n\n\n\n\nvariable\n\n\nfrequencies\n\n\nratio\n\n\ngrade\n\n\ncumulative\n\n\n\n\n\n\nAge\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n10\n\n\n\n\nAge_group\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n20\n\n\n\n\nBloodPressure\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n30\n\n\n\n\nBMI\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n40\n\n\n\n\nDiabetesPedigreeFunction\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n50\n\n\n\n\nGlucose\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n60\n\n\n\n\nInsulin\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n70\n\n\n\n\nOutcome\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n80\n\n\n\n\nPregnancies\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n90\n\n\n\n\nSkinThickness\n\n\n230\n\n\n0.3\n\n\nBad\n\n\n100\n\n\n\n\n\n\n\n\nPlots showing the frequency of missing values\n\n\n# Plot the insersect of the columns with missing values\n# This plot visualizes the table above\nna.dataset |>\n  plot_na_pareto(only_na = TRUE)"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#advanced-exploration-of-missing-values-nas",
    "href": "ImputatingLikeDataScientist.html#advanced-exploration-of-missing-values-nas",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.8 Advanced Exploration of Missing Values (NAs)",
    "text": "5.8 Advanced Exploration of Missing Values (NAs)\n\nIntersect plot that shows, for every combination of columns relevant, how many missing values are common\nOrange boxes are the columns in question\nx axis (top green bar plots) show the number of missing values in that column\ny axis (right green bars) show the number of missing values in the columns in orange blocks\n\n\n# Plot the insersect of the 5 columns with the most missing values\n# This means that some combinations of columns have missing values in the same row\nna.dataset |>\n  select(BloodPressure, Glucose, Age) |>\n  plot_na_intersect(only_na = TRUE) \n\n\n\n\n\n\n5.8.1 Determining if NA Observations are the Same\n\nMissing values can be the same observation across several columns, this is not shown above\nThe visdat package can solve this with the vis_miss() function which shows the rows with missing values through ggplotly()\nHere we will show ALL columns with NAs, and you can zoom into individual rows (interactive plot)\nNOTE: This line will make the HTML rendering take a while…\n\n\n# Interactive plotly() plot of all NA values to examine every row\nna.dataset |>\n select(BloodPressure, Glucose, Age) |>\n vis_miss() |>\n ggplotly()"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#impute-outliers-and-nas",
    "href": "ImputatingLikeDataScientist.html#impute-outliers-and-nas",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.9 Impute Outliers and NAs",
    "text": "5.9 Impute Outliers and NAs\nRemoving outliers and NAs can be tricky, but there are methods to do so. I will go over several, and discuss benefits and costs to each.\nThe principle goal for all imputation is to find the method that does not change the distribution too much (or oddly).\n\nNOTE: imputation should only be used when missing data is unavoidable and probably limited to 10% of your data being outliers / missing data (though some argue imputation is necessary between 30-60%). Ask what the cause is for the outlier and missing data.\n\n\n5.9.1 Classifying Outliers\nBefore imputing outliers, you will want to diagnose whether it’s they are natural outliers or not. We will not be looking at “Insulin” for example across Age_group, because there are several NAs, which we will impute below.\n\n# Box plot\ndataset %>% # Set the simulated normal data as a data frame\n  ggplot(aes(x = Insulin, y = Age_group, fill = Age_group)) + # Create a ggplot\n  geom_boxplot(width = 0.5, outlier.size = 2, outlier.alpha = 0.5) +\n  xlab(\"Insulin (mg/dL)\") +  # Relabel the x axis label\n  ylab(\"Age group\") + # Remove the y axis label\n  scale_fill_OkabeIto() + # Change the color scheme for the fill criteria\n  theme(legend.position = \"none\")  # Remove the legend \n\n\n\n\nNow let’s say that we want to impute extreme values and remove outliers that don’t make sense, such as Insulin levels > 600 mg/dL: values greater than this induce a diabetic coma.\nWe remove outliers using imputate_outlier() and replace them with values that are estimates based on the existing data\n\nmean: arithmetic mean\nmedian: median\nmode: mode\ncapping: Impute the upper outliers with 95 percentile, and impute the bottom outliers with 5 percentile - aka Winsorizing\n\n\n\n5.9.2 Mean Imputation\nThe mean of the observed values for each variable is computed and the outliers for that variable are imputed by this mean\n\n# Raw summary, output suppressed\nmean_out_imp_insulin <- dataset |>\n  select(Insulin) |>\n  filter(Insulin < 600) |>\n  imputate_outlier(Insulin, method = \"mean\")\n\n# HTML table showing the summary statistics of our imputation\nmean_out_imp_insulin |>\n  summary() |>\n  kable() |>\n  kable_styling()\n\nImpute outliers with mean\n\n* Information of Imputation (before vs after)\n                    Original Imputation\ndescribed_variables \"value\"  \"value\"   \nn                   \"764\"    \"764\"     \nna                  \"0\"      \"0\"       \nmean                \"76\"     \"63\"      \nsd                  \"106\"    \" 77\"     \nse_mean             \"3.8\"    \"2.8\"     \nIQR                 \"126\"    \"110\"     \nskewness            \"1.8\"    \"1.1\"     \nkurtosis            \"3.90\"   \"0.28\"    \np00                 \"0\"      \"0\"       \np01                 \"0\"      \"0\"       \np05                 \"0\"      \"0\"       \np10                 \"0\"      \"0\"       \np20                 \"0\"      \"0\"       \np25                 \"0\"      \"0\"       \np30                 \"0\"      \"0\"       \np40                 \"0\"      \"0\"       \np50                 \"24\"     \"24\"      \np60                 \"71\"     \"71\"      \np70                 \"105\"    \" 92\"     \np75                 \"126\"    \"110\"     \np80                 \"147\"    \"130\"     \np90                 \"207\"    \"180\"     \np95                 \"285\"    \"215\"     \np99                 \"482\"    \"284\"     \np100                \"579\"    \"310\"     \n\n\n\n\n \n  \n      \n    Original \n    Imputation \n  \n \n\n  \n    described_variables \n    value \n    value \n  \n  \n    n \n    764 \n    764 \n  \n  \n    na \n    0 \n    0 \n  \n  \n    mean \n    76 \n    63 \n  \n  \n    sd \n    106 \n    77 \n  \n  \n    se_mean \n    3.8 \n    2.8 \n  \n  \n    IQR \n    126 \n    110 \n  \n  \n    skewness \n    1.8 \n    1.1 \n  \n  \n    kurtosis \n    3.90 \n    0.28 \n  \n  \n    p00 \n    0 \n    0 \n  \n  \n    p01 \n    0 \n    0 \n  \n  \n    p05 \n    0 \n    0 \n  \n  \n    p10 \n    0 \n    0 \n  \n  \n    p20 \n    0 \n    0 \n  \n  \n    p25 \n    0 \n    0 \n  \n  \n    p30 \n    0 \n    0 \n  \n  \n    p40 \n    0 \n    0 \n  \n  \n    p50 \n    24 \n    24 \n  \n  \n    p60 \n    71 \n    71 \n  \n  \n    p70 \n    105 \n    92 \n  \n  \n    p75 \n    126 \n    110 \n  \n  \n    p80 \n    147 \n    130 \n  \n  \n    p90 \n    207 \n    180 \n  \n  \n    p95 \n    285 \n    215 \n  \n  \n    p99 \n    482 \n    284 \n  \n  \n    p100 \n    579 \n    310 \n  \n\n\n\n\n\n\n# Visualization of the mean imputation\nmean_out_imp_insulin |>\n  plot()\n\n\n\n\n\n\n5.9.3 Median Imputation\nThe median of the observed values for each variable is computed and the outliers for that variable are imputed by this median\n\n# Raw summary, output suppressed\nmed_out_imp_insulin <- dataset |>\n  select(Insulin) |>\n  filter(Insulin < 600) |>\n  imputate_outlier(Insulin, method = \"median\")\n\n# HTML table showing the summary statistics of our imputation\nmed_out_imp_insulin |>\n  summary() |>\n  kable() |>\n  kable_styling()\n\nImpute outliers with median\n\n* Information of Imputation (before vs after)\n                    Original Imputation\ndescribed_variables \"value\"  \"value\"   \nn                   \"764\"    \"764\"     \nna                  \"0\"      \"0\"       \nmean                \"76\"     \"60\"      \nsd                  \"106\"    \" 77\"     \nse_mean             \"3.8\"    \"2.8\"     \nIQR                 \"126\"    \"110\"     \nskewness            \"1.8\"    \"1.1\"     \nkurtosis            \"3.90\"   \"0.35\"    \np00                 \"0\"      \"0\"       \np01                 \"0\"      \"0\"       \np05                 \"0\"      \"0\"       \np10                 \"0\"      \"0\"       \np20                 \"0\"      \"0\"       \np25                 \"0\"      \"0\"       \np30                 \"0\"      \"0\"       \np40                 \"0\"      \"0\"       \np50                 \"24\"     \"24\"      \np60                 \"71\"     \"56\"      \np70                 \"105\"    \" 92\"     \np75                 \"126\"    \"110\"     \np80                 \"147\"    \"130\"     \np90                 \"207\"    \"180\"     \np95                 \"285\"    \"215\"     \np99                 \"482\"    \"284\"     \np100                \"579\"    \"310\"     \n\n\n\n\n \n  \n      \n    Original \n    Imputation \n  \n \n\n  \n    described_variables \n    value \n    value \n  \n  \n    n \n    764 \n    764 \n  \n  \n    na \n    0 \n    0 \n  \n  \n    mean \n    76 \n    60 \n  \n  \n    sd \n    106 \n    77 \n  \n  \n    se_mean \n    3.8 \n    2.8 \n  \n  \n    IQR \n    126 \n    110 \n  \n  \n    skewness \n    1.8 \n    1.1 \n  \n  \n    kurtosis \n    3.90 \n    0.35 \n  \n  \n    p00 \n    0 \n    0 \n  \n  \n    p01 \n    0 \n    0 \n  \n  \n    p05 \n    0 \n    0 \n  \n  \n    p10 \n    0 \n    0 \n  \n  \n    p20 \n    0 \n    0 \n  \n  \n    p25 \n    0 \n    0 \n  \n  \n    p30 \n    0 \n    0 \n  \n  \n    p40 \n    0 \n    0 \n  \n  \n    p50 \n    24 \n    24 \n  \n  \n    p60 \n    71 \n    56 \n  \n  \n    p70 \n    105 \n    92 \n  \n  \n    p75 \n    126 \n    110 \n  \n  \n    p80 \n    147 \n    130 \n  \n  \n    p90 \n    207 \n    180 \n  \n  \n    p95 \n    285 \n    215 \n  \n  \n    p99 \n    482 \n    284 \n  \n  \n    p100 \n    579 \n    310 \n  \n\n\n\n\n\n\n# Visualization of the median imputation\nmed_out_imp_insulin |>\n  plot()\n\n\n\n\n\n\n5.9.3.1 Pros & Cons of Using the Mean or Median Imputation\nPros:\n\nEasy and fast.\nWorks well with small numerical datasets.\n\nCons:\n\nDoesn’t factor the correlations between features. It only works on the column level.\nWill give poor results on encoded categorical features (do NOT use it on categorical features).\nNot very accurate.\nDoesn’t account for the uncertainty in the imputations.\n\n\n\n\n\n5.9.4 Mode Imputation\nThe mode of the observed values for each variable is computed and the outliers for that variable are imputed by this mode\n\n# Raw summary, output suppressed\nmode_out_imp_insulin <- dataset |>\n  select(Insulin) |>\n  filter(Insulin < 600) |>\n  imputate_outlier(Insulin, method = \"mode\")\n\n# HTML table showing the summary statistics of our imputation\nmode_out_imp_insulin |>\n  summary() |>\n  kable() |>\n  kable_styling()\n\nImpute outliers with mode\n\n* Information of Imputation (before vs after)\n                    Original Imputation\ndescribed_variables \"value\"  \"value\"   \nn                   \"764\"    \"764\"     \nna                  \"0\"      \"0\"       \nmean                \"76\"     \"59\"      \nsd                  \"106\"    \" 78\"     \nse_mean             \"3.8\"    \"2.8\"     \nIQR                 \"126\"    \"110\"     \nskewness            \"1.8\"    \"1.1\"     \nkurtosis            \"3.90\"   \"0.32\"    \np00                 \"0\"      \"0\"       \np01                 \"0\"      \"0\"       \np05                 \"0\"      \"0\"       \np10                 \"0\"      \"0\"       \np20                 \"0\"      \"0\"       \np25                 \"0\"      \"0\"       \np30                 \"0\"      \"0\"       \np40                 \"0\"      \"0\"       \np50                 \"24\"     \" 0\"      \np60                 \"71\"     \"56\"      \np70                 \"105\"    \" 92\"     \np75                 \"126\"    \"110\"     \np80                 \"147\"    \"130\"     \np90                 \"207\"    \"180\"     \np95                 \"285\"    \"215\"     \np99                 \"482\"    \"284\"     \np100                \"579\"    \"310\"     \n\n\n\n\n \n  \n      \n    Original \n    Imputation \n  \n \n\n  \n    described_variables \n    value \n    value \n  \n  \n    n \n    764 \n    764 \n  \n  \n    na \n    0 \n    0 \n  \n  \n    mean \n    76 \n    59 \n  \n  \n    sd \n    106 \n    78 \n  \n  \n    se_mean \n    3.8 \n    2.8 \n  \n  \n    IQR \n    126 \n    110 \n  \n  \n    skewness \n    1.8 \n    1.1 \n  \n  \n    kurtosis \n    3.90 \n    0.32 \n  \n  \n    p00 \n    0 \n    0 \n  \n  \n    p01 \n    0 \n    0 \n  \n  \n    p05 \n    0 \n    0 \n  \n  \n    p10 \n    0 \n    0 \n  \n  \n    p20 \n    0 \n    0 \n  \n  \n    p25 \n    0 \n    0 \n  \n  \n    p30 \n    0 \n    0 \n  \n  \n    p40 \n    0 \n    0 \n  \n  \n    p50 \n    24 \n    0 \n  \n  \n    p60 \n    71 \n    56 \n  \n  \n    p70 \n    105 \n    92 \n  \n  \n    p75 \n    126 \n    110 \n  \n  \n    p80 \n    147 \n    130 \n  \n  \n    p90 \n    207 \n    180 \n  \n  \n    p95 \n    285 \n    215 \n  \n  \n    p99 \n    482 \n    284 \n  \n  \n    p100 \n    579 \n    310 \n  \n\n\n\n\n\n\n# Visualization of the mode imputation\nmode_out_imp_insulin |>\nplot()\n\n\n\n\n\n\n5.9.4.1 Pros & Cons of Using the Mode Imputation\nPros:\n\nWorks well with categorical features.\n\nCons:\n\nIt also doesn’t factor the correlations between features.\nIt can introduce bias in the data.\n\n\n\n\n\n5.9.5 Capping Imputation (aka Winsorizing)\nThe Percentile Capping is a method of Imputing the outlier values by replacing those observations outside the lower limit with the value of 5th percentile and those that lie above the upper limit, with the value of 95th percentile of the same dataset.\n\n# Raw summary, output suppressed\ncap_out_imp_insulin <- dataset |>\n  select(Insulin) |>\n  filter(Insulin < 600) |>\n  imputate_outlier(Insulin, method = \"capping\")\n\n# HTML table showing the summary statistics of our imputation\ncap_out_imp_insulin |>\n  summary() |>\n  kable() |>\n  kable_styling()\n\nImpute outliers with capping\n\n* Information of Imputation (before vs after)\n                    Original Imputation\ndescribed_variables \"value\"  \"value\"   \nn                   \"764\"    \"764\"     \nna                  \"0\"      \"0\"       \nmean                \"76\"     \"71\"      \nsd                  \"106\"    \" 89\"     \nse_mean             \"3.8\"    \"3.2\"     \nIQR                 \"126\"    \"126\"     \nskewness            \"1.8\"    \"1.1\"     \nkurtosis            \"3.895\"  \"0.017\"   \np00                 \"0\"      \"0\"       \np01                 \"0\"      \"0\"       \np05                 \"0\"      \"0\"       \np10                 \"0\"      \"0\"       \np20                 \"0\"      \"0\"       \np25                 \"0\"      \"0\"       \np30                 \"0\"      \"0\"       \np40                 \"0\"      \"0\"       \np50                 \"24\"     \"24\"      \np60                 \"71\"     \"71\"      \np70                 \"105\"    \"105\"     \np75                 \"126\"    \"126\"     \np80                 \"147\"    \"147\"     \np90                 \"207\"    \"207\"     \np95                 \"285\"    \"285\"     \np99                 \"482\"    \"285\"     \np100                \"579\"    \"310\"     \n\n\n\n\n \n  \n      \n    Original \n    Imputation \n  \n \n\n  \n    described_variables \n    value \n    value \n  \n  \n    n \n    764 \n    764 \n  \n  \n    na \n    0 \n    0 \n  \n  \n    mean \n    76 \n    71 \n  \n  \n    sd \n    106 \n    89 \n  \n  \n    se_mean \n    3.8 \n    3.2 \n  \n  \n    IQR \n    126 \n    126 \n  \n  \n    skewness \n    1.8 \n    1.1 \n  \n  \n    kurtosis \n    3.895 \n    0.017 \n  \n  \n    p00 \n    0 \n    0 \n  \n  \n    p01 \n    0 \n    0 \n  \n  \n    p05 \n    0 \n    0 \n  \n  \n    p10 \n    0 \n    0 \n  \n  \n    p20 \n    0 \n    0 \n  \n  \n    p25 \n    0 \n    0 \n  \n  \n    p30 \n    0 \n    0 \n  \n  \n    p40 \n    0 \n    0 \n  \n  \n    p50 \n    24 \n    24 \n  \n  \n    p60 \n    71 \n    71 \n  \n  \n    p70 \n    105 \n    105 \n  \n  \n    p75 \n    126 \n    126 \n  \n  \n    p80 \n    147 \n    147 \n  \n  \n    p90 \n    207 \n    207 \n  \n  \n    p95 \n    285 \n    285 \n  \n  \n    p99 \n    482 \n    285 \n  \n  \n    p100 \n    579 \n    310 \n  \n\n\n\n\n\n\n# Visualization of the capping imputation\ncap_out_imp_insulin |>\n  plot()\n\n\n\n\n\n\n5.9.5.1 Pros and Cons of Capping\nPros:\n\nNot influenced by extreme values\n\nCons:\n\nCapping only modifies the smallest and largest values slightly. This is generally not a good idea since it means we’re just modifying data values for the sake of modifications.\nIf no extreme outliers are present, Winsorization may be unnecessary."
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#imputing-nas",
    "href": "ImputatingLikeDataScientist.html#imputing-nas",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.10 Imputing NAs",
    "text": "5.10 Imputing NAs\nI will only be addressing one type of NA imputation using imputate_na() (but note you can use mean, median, and mode as well):\n\nknn: K-nearest neighbors (KNN)\nrpart: Recursive Partitioning and Regression Trees (rpart)\nmice: Multivariate Imputation by Chained Equations (MICE)\n\nSince our normal dataset has no NA values, we will use the na.dataset we created earlier.\n\n5.10.1 K-Nearest Neighbor (KNN) Imputation\nKNN is a machine learning algorithm that classifies data by similarity. This in effect clusters data into similar groups. The algorithm predicts values of new data to replace NA values based on how closely they resembles training data points, such as by comparing across other columns.\nHere’s a visual example using the clara() function from the cluster package to run a KNN algorithm on our dataset, where three clusters are created by the algorithm.\n\n# KNN plot of our dataset without categories\nautoplot(clara(dataset[-5], 3)) +\n  scale_color_OkabeIto()\n\n\n\n\n\n# Raw summary, output suppressed\nknn_na_imp_insulin <- na.dataset |>\n  imputate_na(Insulin, method = \"knn\")\n\n# Plot showing the results of our imputation\nknn_na_imp_insulin |>\n  plot()\n\n\n\n\n\n5.10.1.1 Pros & Cons of Using KNN Imputation\nPro:\n\nPossibly much more accurate than mean, median, or mode imputation for some data sets.\n\nCons:\n\nKNN is computationally expensive because it stores the entire training dataset into computer memory.\nKNN is very sensitive to outliers, so you would have to imputate these first.\n\n\n\n\n5.10.2 Recursive Partitioning and Regression Trees (rpart)\nrpart is a decision tree machine learning algorithm that builds classification or regression models through a two stage process, which can be thought of as binary trees. The algorithm splits the data into subsets, which move down other branches of the tree until a termination criteria is reached.\nFor example, if we are missing a value for Age_group a first decision could be whether the associated Age is within a series of yes or no criteria\n\n\n\n\n\n\n# Raw summary, output suppressed\nrpart_na_imp_insulin <- na.dataset |>\n  imputate_na(Insulin, method = \"rpart\")\n\n# Plot showing the results of our imputation\nrpart_na_imp_insulin |>\n  plot()\n\n\n\n\n\n5.10.2.1 Pros & Cons of Using rpart Imputation\nPros:\n\nGood for categorical data because approximations are easier to compare across categories than continuous variables.\nNot sensitive to outliers.\n\nCons:\n\nCan over fit the data as they grow.\nSpeed decreases with more data columns.\n\n\n\n\n5.10.3 Multivariate Imputation by Chained Equations (MICE)\nMICE is an algorithm that fills missing values multiple times, hence dealing with uncertainty better than other methods. This approach creates multiple copies of the data that can then be analyzed and then pooled into a single dataset.\n\n\n\nImage Credit: Will Badr\n\n\n\n# Raw summary, output suppressed\nmice_na_imp_insulin <- na.dataset |>\n  imputate_na(Insulin, method = \"mice\")\n\n\n iter imp variable\n  1   1  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  1   2  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  1   3  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  1   4  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  1   5  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  2   1  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  2   2  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  2   3  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  2   4  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  2   5  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  3   1  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  3   2  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  3   3  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  3   4  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  3   5  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  4   1  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  4   2  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  4   3  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  4   4  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  4   5  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  5   1  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  5   2  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  5   3  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  5   4  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n  5   5  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  DiabetesPedigreeFunction  Age  Outcome  Age_group\n\n# Plot showing the results of our imputation\nmice_na_imp_insulin |>\n  plot()\n\n\n\n\n\n5.10.3.1 Pros & Cons of MICE Imputation\nPros:\n\nMultiple imputations are more accurate than a single imputation.\nThe chained equations are very flexible to data types, such as categorical and ordinal.\n\nCons:\n\nYou have to round the results for ordinal data because resulting data points are too great or too small (floating-points)."
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#produce-an-html-normality-summary-of-a-data-set",
    "href": "ImputatingLikeDataScientist.html#produce-an-html-normality-summary-of-a-data-set",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.11 Produce an HTML Normality Summary of a Data Set",
    "text": "5.11 Produce an HTML Normality Summary of a Data Set\n\n# Remove the '#' below to reproduce an HTML from an R script. \n\n# transformation_web_report(dataset)"
  },
  {
    "objectID": "TransformingLikeDataTrans.html",
    "href": "TransformingLikeDataTrans.html",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "",
    "text": "Using data transformation to correct non-normality in data"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#load-and-examine-a-data-set",
    "href": "ImputatingLikeDataScientist.html#load-and-examine-a-data-set",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.4 Load and Examine a Data Set",
    "text": "5.4 Load and Examine a Data Set\n\n# Let's load a data set from the diabetes data set\ndataset <- read.csv(here(\"EDA_In_R_Summer_Book\", \"data\", \"diabetes.csv\")) |>\n  # Add a categorical group\n  mutate(Age_group = ifelse(Age >= 21 & Age <= 30, \"Young\", \n                            ifelse(Age > 30 & Age <=50, \"Middle\", \n                                   \"Elderly\")),\n         Age_group = fct_rev(Age_group))\n\n# What does the data look like?\ndataset |>\n  head() |>\n  formattable()\n\n\n\n\n\n\nPregnancies\n\n\nGlucose\n\n\nBloodPressure\n\n\nSkinThickness\n\n\nInsulin\n\n\nBMI\n\n\nDiabetesPedigreeFunction\n\n\nAge\n\n\nOutcome\n\n\nAge_group\n\n\n\n\n\n\n6\n\n\n148\n\n\n72\n\n\n35\n\n\n0\n\n\n34\n\n\n0.63\n\n\n50\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n85\n\n\n66\n\n\n29\n\n\n0\n\n\n27\n\n\n0.35\n\n\n31\n\n\n0\n\n\nMiddle\n\n\n\n\n8\n\n\n183\n\n\n64\n\n\n0\n\n\n0\n\n\n23\n\n\n0.67\n\n\n32\n\n\n1\n\n\nMiddle\n\n\n\n\n1\n\n\n89\n\n\n66\n\n\n23\n\n\n94\n\n\n28\n\n\n0.17\n\n\n21\n\n\n0\n\n\nYoung\n\n\n\n\n0\n\n\n137\n\n\n40\n\n\n35\n\n\n168\n\n\n43\n\n\n2.29\n\n\n33\n\n\n1\n\n\nMiddle\n\n\n\n\n5\n\n\n116\n\n\n74\n\n\n0\n\n\n0\n\n\n26\n\n\n0.20\n\n\n30\n\n\n0\n\n\nYoung"
  },
  {
    "objectID": "ImputatingLikeDataScientist.html#produce-an-html-transformation-summary",
    "href": "ImputatingLikeDataScientist.html#produce-an-html-transformation-summary",
    "title": "5  Exploratory Data Analysis in R - Imputating like a Data Scientist",
    "section": "5.11 Produce an HTML Transformation Summary",
    "text": "5.11 Produce an HTML Transformation Summary\n\n# Remove the '#' below to reproduce an HTML from an R script. \n\n# transformation_web_report(dataset)"
  },
  {
    "objectID": "TransformingLikeDataTrans.html#produce-an-html-transformation-summary",
    "href": "TransformingLikeDataTrans.html#produce-an-html-transformation-summary",
    "title": "4  Exploratory Data Analysis in R - Transforming like a Data… Transformer",
    "section": "4.8 Produce an HTML Transformation Summary",
    "text": "4.8 Produce an HTML Transformation Summary\n\n# Remove the '#' below to reproduce an HTML from an R script. \n# transformation_web_report(dataset)"
  },
  {
    "objectID": "ExploringLikeDataAdventurer.html#produce-an-html-normality-summary",
    "href": "ExploringLikeDataAdventurer.html#produce-an-html-normality-summary",
    "title": "3  Exploratory Data Analysis in R - Exploring like a Data Adventurer",
    "section": "3.9 Produce an HTML Normality Summary",
    "text": "3.9 Produce an HTML Normality Summary\n\n# Remove the '#' below to reproduce an HTML from an R script. \n#eda_web_report(dataset)\n\n\n\n\n\nMeredith, Laura, S. Nemiah Ladd, and Christiane Werner. 2021. “Data for \"Ecosystem Fluxes During Drought and Recovery in an Experimental Forest\".” University of Arizona Research Data Repository. https://doi.org/10.25422/AZU.DATA.14632593.V1."
  }
]