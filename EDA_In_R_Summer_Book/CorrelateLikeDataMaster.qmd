---
bibliography: references.bib
---

# Exploratory Data Analysis in R - Correlate Like a Data Master

```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Purpose of workshop

**Assess relationships within a novel data set using publication quality tables and plots**

------------------------------------------------------------------------

## Objectives

1.  Describe and visualize correlations between numerical variables
2.  Visualize correlations of all numerical variables within groups
3.  Describe and visualize relationships based on target variables
4.  Plot relationships using publication quality plots in `ggplot()`

------------------------------------------------------------------------

### Required setup

#### We first need to prepare our environment with the necessary packages

```{r}
options(repos = list(CRAN = "http://cran.rstudio.com/"))

install.packages("pacman")

library(pacman)

p_load(colorblindr,
       dlookr,
       formattable,
       GGally,
       ggdist,
       ggpubr,
       ggridges,
       here, 
       papeR,
       tidyverse)

# Set global ggplot() theme
# Theme pub_clean() from the ggpubr package with base text size = 16
theme_set(theme_pubclean(base_size = 12)) 
# All axes titles to their respective far right sides
theme_update(axis.title = element_text(hjust = 1))
# Remove axes ticks
theme_update(axis.ticks = element_blank()) 
# Remove legend key
theme_update(legend.key = element_blank())
```

------------------------------------------------------------------------

## Load the Examine a Data Set

We will be using open source data from UArizona researchers that investigates the effects of climate change on canopy trees. [@meredith2021]

```{r}
# Let's load the canopy tree data set
dataset <- read.csv(here("EDA_In_R_Summer_Book", "data", "Data_Fig2_Repo.csv"))

# What does the data look like?
dataset |>
  head() |>
  formattable()
```

------------------------------------------------------------------------

## Describe and Visualize Correlations

[Correlations](https://en.wikipedia.org/wiki/Correlation) are a statistical relationship between two numerical variables, may or may not be causal. Exploring correlations in your data allows you determine data independence, a major [assumption of parametric statistics](https://www.statology.org/parametric-tests-assumptions/), which means your variables are both randomly collected.

#### If you're interested in some underlying statistics... 

Note that the `dlookr` default correlation is the [Pearson's $r$ coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficienthttps://en.wikipedia.org/wiki/Pearson_correlation_coefficient), but you can specify any method you would like: `correlate(dataset, method = "")`, where the method can be `"pearson"` for Pearson's $r$, `"spearman"` for [Spearman's ](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)\$\\rho\$, or "kendall" for [Kendall's](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient) $\tau$. The main differences are that Pearson's $r$ assumes a normal distribution for ALL numerical variables, whereas Spearman's $\rho$ and Kendall's $\tau$ do not, but Spearman's $\rho$ requires $N > 10$, and Kendall's $\tau$ does not. Notably, Kendall's $\tau$ performs as well as Spearman's $\rho$ when $N > 10$, so its best to just use Kendall's $\tau$ when data are not normally distributed.

```{r}
# Table of correlations between numerical variables (we are sticking to the default Pearson's r coefficient)
correlate(dataset) |>
  formattable()
```

```{r}
# Correlation matrix of numerical variables
dataset |>
plot_correlate()
```

------------------------------------------------------------------------

## Visualize Correlations within Groups

If we have groups that we will compare later on, it is a good idea to see how each numerical variable correlates within these groups.

```{r}
dataset |>
  group_by(Group) |>
  plot_correlate()
```

This is great, we have our correlations within groups! However, the correlation matrices aren't always the most intuitive, so let's plot!

We will be using the `ggpairs()` function within the `GGally` package. Specifically, we are looking at the correlations between predawn leaf water potential `pLWP` and midday leaf water potential `mLWP`. Leaf water potential is a key indicator for how stressed plants are in droughts.

```{r}
dataset |> 
  dplyr::select(Group, pLWP, mLWP) |>
  ggpairs(aes(color = Group, alpha = 0.5)) +
  theme(strip.background = element_blank()) + # I don't like the facet strips
  scale_fill_OkabeIto() +
  scale_color_OkabeIto()
```

------------------------------------------------------------------------

## Describe and Visualize Relationships Based on Target Variables

------------------------------------------------------------------------

### Linear Regression in R

[Linear regression](https://en.wikipedia.org/wiki/Linear_regression) is a hypothesis testing statistical analysis that tests to what extent the relationship between two numerical variables is linear. This is accomplished by applying the best linear fix to a set of (x, y) points, producing a slope (described by the $\beta$ coefficient) and determining whether this slope is significantly different from 0. The extent in which the slope is greater than zero influences $p$ value (significance denoted by $p < 0.05$).

Here's an example from our data using the `lm()` function.

```{r}
Reg <- lm(pLWP ~ Sap_Flow, data = dataset)

summary(Reg) 
```

-   `Estimate`: The slope of the linear fit, or $\beta$

-   `Std. Error`: A measure of uncertainty - estimated standard deviation of the `Estimate`

    -   You want this measure to be small.

-   `t value`: The descriptive statistic in which the $p$ value is derived.

    -   Larger values mean smaller $p$ values.

-   `Pr(>|t|)` The $p$ value.

    -   The value is derived from the [T distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution). For more information, see [here](https://www.nature.com/articles/nmeth.2698).

-   `Multiple R-squared`: The proportion of the variance in the dependent variable that is predictable from the independent variable.

    -   i.e., an r-squared of 0.5 means that 50% of the variance in *"y"* is predictable from *"x"*

-   `Adjusted R-squared`: The proportion of variation explained by only the independent variables that actually affect the dependent variable.

    -   Adj. r-squared penalizes you for adding more independent variables.

------------------------------------------------------------------------

### Target Variables

`Target variables` are essentially numerical or categorical variables that you want to relate others to in a data frame. `dlookr` does this through the `target_by()` function, which is similar to `group_by()` in `dplyr`. The `relate()` function then briefly analyzes the relationship between the target variable and the variables of interest.

### Numerical Target Variables

```{r}
# The numerical target variable that we want
num <- target_by(dataset, Sap_Flow)

# Relating the variable of interest to the 
num_num <- relate(num, pLWP)

# Summary of the regression analysis - the same as the summary from lm()
summary(num_num)
```

```{r}
# Plotting the linear relationship
plot(num_num)
```

### Categorical Target Variables: Numerical Variable of Interest

```{r}

```
